{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attack_method='Basic', cuda=True, dataset='ogbn-arxiv', debug=True, defense_mode='none', device_id=0, dis_weight=1, dropout=0.5, epochs=200, hidden=128, homo_boost_thrd=0.5, homo_loss_weight=1, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.3, seed=10, selection_method='cluster', target_class=0, target_loss_weight=1, test_model='GCN', thrd=0.5, train_lr=0.02, trigger_prob=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)\n",
      "Length of training set: 33868\n",
      "Training benign model Finished!\n",
      "Total time elapsed: 9.1381s\n",
      "Benign CA: 0.6725\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from models.GCN import GCN\n",
    "from models.GCN_Encoder import GCN_Encoder\n",
    "from torch_geometric.datasets import Planetoid, WebKB, WikipediaNetwork,Reddit,Reddit2,Flickr,Yelp,PPI\n",
    "from torch_geometric.utils import to_dense_adj,dense_to_sparse\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "# from torch_geometric.loader import DataLoader\n",
    "from help_funcs import prune_unrelated_edge,prune_unrelated_edge_isolated,select_target_nodes\n",
    "import help_funcs\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "        default=True, help='debug mode')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--seed', type=int, default=10, help='Random seed.')\n",
    "parser.add_argument('--model', type=str, default='GCN', help='model',\n",
    "                    choices=['GCN','GAT','GraphSage','GIN'])\n",
    "parser.add_argument('--dataset', type=str, default='ogbn-arxiv', \n",
    "                    help='Dataset',\n",
    "                    choices=['Cora','Citeseer','Pubmed','PPI','Flickr','ogbn-arxiv','Reddit','Reddit2','Yelp'])\n",
    "parser.add_argument('--train_lr', type=float, default=0.02,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--hidden', type=int, default=128,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--thrd', type=float, default=0.5)\n",
    "parser.add_argument('--target_class', type=int, default=0)\n",
    "parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--epochs', type=int,  default=200, help='Number of epochs to train benign and backdoor model.')\n",
    "parser.add_argument('--trojan_epochs', type=int,  default=200, help='Number of epochs to train trigger generator.')\n",
    "parser.add_argument('--inner', type=int,  default=1, help='Number of inner')\n",
    "# backdoor setting\n",
    "parser.add_argument('--lr', type=float, default=0.01,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--trigger_size', type=int, default=3,\n",
    "                    help='tirgger_size')\n",
    "parser.add_argument('--vs_ratio', type=float, default=0.01,\n",
    "                    help=\"ratio of poisoning nodes relative to the full graph\")\n",
    "# defense setting\n",
    "parser.add_argument('--defense_mode', type=str, default=\"none\",\n",
    "                    choices=['prune', 'isolate', 'none'],\n",
    "                    help=\"Mode of defense\")\n",
    "parser.add_argument('--prune_thr', type=float, default=0.3,\n",
    "                    help=\"Threshold of prunning edges\")\n",
    "parser.add_argument('--target_loss_weight', type=float, default=1,\n",
    "                    help=\"Weight of optimize outter trigger generator\")\n",
    "parser.add_argument('--homo_loss_weight', type=float, default=1,\n",
    "                    help=\"Weight of optimize similarity loss\")\n",
    "parser.add_argument('--homo_boost_thrd', type=float, default=0.5,\n",
    "                    help=\"Threshold of increase similarity\")\n",
    "# attack setting\n",
    "parser.add_argument('--dis_weight', type=float, default=1,\n",
    "                    help=\"Weight of cluster distance\")\n",
    "parser.add_argument('--attack_method', type=str, default='Basic',\n",
    "                    choices=['Rand_Gene','Rand_Samp','Basic','None'],\n",
    "                    help='Method to select idx_attach for training trojan model (none means randomly select)')\n",
    "parser.add_argument('--trigger_prob', type=float, default=0.5,\n",
    "                    help=\"The probability to generate the trigger's edges in random method\")\n",
    "parser.add_argument('--selection_method', type=str, default='cluster',\n",
    "                    choices=['loss','conf','cluster','none'],\n",
    "                    help='Method to select idx_attach for training trojan model (none means randomly select)')\n",
    "parser.add_argument('--test_model', type=str, default='GCN',\n",
    "                    choices=['GCN','GAT','GraphSage','GIN'],\n",
    "                    help='Model used to attack')\n",
    "\n",
    "# GPU setting\n",
    "parser.add_argument('--device_id', type=int, default=0,\n",
    "                    help=\"Threshold of prunning edges\")\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_known_args()[0]\n",
    "args.cuda =  not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(('cuda:{}' if torch.cuda.is_available() else 'cpu').format(args.device_id))\n",
    "# device2 = torch.device(('cuda:{}' if torch.cuda.is_available() else 'cpu').format(args.device_id+1))\n",
    "\n",
    "\n",
    "#%%\n",
    "from torch_geometric.utils import to_undirected\n",
    "import torch_geometric.transforms as T\n",
    "transform = T.Compose([T.NormalizeFeatures()])\n",
    "\n",
    "np.random.seed(11) # fix the random seed is important\n",
    "if(args.dataset == 'Cora' or args.dataset == 'Citeseer' or args.dataset == 'Pubmed'):\n",
    "    dataset = Planetoid(root='./data/', \\\n",
    "                        name=args.dataset,\\\n",
    "                        transform=transform)\n",
    "elif(args.dataset == 'Flickr'):\n",
    "    dataset = Flickr(root='./data/Flickr/', \\\n",
    "                    transform=transform)\n",
    "elif(args.dataset == 'PPI'):\n",
    "    dataset = PPI(root='./data/PPI/', \n",
    "                split='train', transform=None)\n",
    "elif(args.dataset == 'Reddit2'):\n",
    "    dataset = Reddit2(root='./data/Reddit2/', \\\n",
    "                    transform=transform)\n",
    "elif(args.dataset == 'ogbn-arxiv'):\n",
    "    # Download and process data at './dataset/ogbg_molhiv/'\n",
    "    dataset = PygNodePropPredDataset(name = 'ogbn-arxiv', root='./data/')\n",
    "    split_idx = dataset.get_idx_split() \n",
    "elif(args.dataset == 'Yelp'):\n",
    "    # Download and process data at './dataset/ogbg_molhiv/'\n",
    "    dataset = Yelp(root='./data/Yelp/')\n",
    "    # idx_train, idx_val, idx_test = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "if(args.dataset == 'ogbn-arxiv'):\n",
    "    nNode = data.x.shape[0]\n",
    "    setattr(data,'train_mask',torch.zeros(nNode, dtype=torch.bool).to(device))\n",
    "    # dataset[0].train_mask = torch.zeros(nEdge, dtype=torch.bool).to(device)\n",
    "    data.val_mask = torch.zeros(nNode, dtype=torch.bool).to(device)\n",
    "    data.test_mask = torch.zeros(nNode, dtype=torch.bool).to(device)\n",
    "    data.y = data.y.squeeze(1)\n",
    "# we build our own train test split \n",
    "from utils import get_split\n",
    "data, idx_train, idx_val, idx_clean_test, idx_atk = get_split(data,device)\n",
    "\n",
    "#%%\n",
    "from torch_geometric.utils import to_undirected\n",
    "from utils import subgraph\n",
    "data.edge_index = to_undirected(data.edge_index)\n",
    "train_edge_index,_, edge_mask = subgraph(torch.bitwise_not(data.test_mask),data.edge_index,relabel_nodes=False)\n",
    "mask_edge_index = data.edge_index[:,torch.bitwise_not(edge_mask)]\n",
    "\n",
    "# In[3]:\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "print(args)\n",
    "\n",
    "# In[6]: \n",
    "import os\n",
    "from models.backdoor import model_construct\n",
    "benign_modelpath = './modelpath/{}_{}_benign.pth'.format(args.model, args.dataset)\n",
    "if(os.path.exists(benign_modelpath)):\n",
    "    # load existing benign model\n",
    "    benign_model = torch.load(benign_modelpath)\n",
    "    benign_model = benign_model.to(device)\n",
    "    # edge_weights = torch.ones([data.edge_index.shape[1]],device=device,dtype=torch.float)\n",
    "    print(\"Loading benign {} model Finished!\".format(args.model))\n",
    "else:\n",
    "    benign_model = model_construct(args,args.model,data,device).to(device) \n",
    "    t_total = time.time()\n",
    "    print(\"Length of training set: {}\".format(len(idx_train)))\n",
    "    benign_model.fit(data.x, train_edge_index, None, data.y, idx_train, idx_val,train_iters=args.epochs,verbose=False)\n",
    "    print(\"Training benign model Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    # Save trained model\n",
    "    # torch.save(benign_model, benign_modelpath)\n",
    "    # print(\"Benign model saved at {}\".format(benign_modelpath))\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "benign_ca = benign_model.test(data.x, data.edge_index, None, data.y,idx_clean_test)\n",
    "print(\"Benign CA: {:.4f}\".format(benign_ca))\n",
    "benign_model = benign_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 33868\n",
      "=== training gcn model ===\n",
      "Epoch 0, training loss: 3.6893434524536133\n",
      "acc_val: 0.1306\n",
      "Epoch 10, training loss: 3.0229945182800293\n",
      "acc_val: 0.1894\n",
      "Epoch 20, training loss: 2.431436061859131\n",
      "acc_val: 0.3566\n",
      "Epoch 30, training loss: 2.0573935508728027\n",
      "acc_val: 0.4880\n",
      "Epoch 40, training loss: 1.831594467163086\n",
      "acc_val: 0.5358\n",
      "Epoch 50, training loss: 1.6789823770523071\n",
      "acc_val: 0.5689\n",
      "Epoch 60, training loss: 1.568912386894226\n",
      "acc_val: 0.5896\n",
      "Epoch 70, training loss: 1.504565715789795\n",
      "acc_val: 0.6112\n",
      "Epoch 80, training loss: 1.459658145904541\n",
      "acc_val: 0.6251\n",
      "Epoch 90, training loss: 1.4360332489013672\n",
      "acc_val: 0.6308\n",
      "Epoch 100, training loss: 1.4004930257797241\n",
      "acc_val: 0.6355\n",
      "Epoch 110, training loss: 1.3869333267211914\n",
      "acc_val: 0.6365\n",
      "Epoch 120, training loss: 1.3648103475570679\n",
      "acc_val: 0.6422\n",
      "Epoch 130, training loss: 1.3539406061172485\n",
      "acc_val: 0.6450\n",
      "Epoch 140, training loss: 1.3477853536605835\n",
      "acc_val: 0.6471\n",
      "Epoch 150, training loss: 1.3383408784866333\n",
      "acc_val: 0.6481\n",
      "Epoch 160, training loss: 1.3359863758087158\n",
      "acc_val: 0.6482\n",
      "Epoch 170, training loss: 1.3287087678909302\n",
      "acc_val: 0.6463\n",
      "Epoch 180, training loss: 1.3183035850524902\n",
      "acc_val: 0.6529\n",
      "Epoch 190, training loss: 1.3105125427246094\n",
      "acc_val: 0.6530\n",
      "=== picking the best model according to the performance on validation ===\n",
      "Training encoder Finished!\n",
      "Total time elapsed: 12.1815s\n",
      "Encoder CA on clean test nodes: 0.6589\n",
      "running k-means on cuda:0..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 160it [02:42,  1.02s/it, center_shift=0.000024, iteration=160, tol=0.000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 28 28 ... 30 24  8]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/project-graph-backdoor/Backdoor/run.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m encoder_output \u001b[39m=\u001b[39m gcn_encoder(data\u001b[39m.\u001b[39mx,train_edge_index,\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(encoder_output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m idx_attach \u001b[39m=\u001b[39m obtain_attach_nodes_by_cluster_gpu(args,y_pred,cluster_centers,unlabeled_idx\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mtolist(),encoder_x,data\u001b[39m.\u001b[39;49my,device,size)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m idx_attach \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(idx_attach)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# kmedoids = cluster.KMedoids(n_clusters=nclass,method='pam')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# kmedoids.fit(encoder_x[seen_node_idx].detach().cpu().numpy())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# idx_attach = obtain_attach_nodes_by_cluster(args,kmedoids,unlabeled_idx.cpu().tolist(),encoder_x,data.y,device,size)\u001b[39;00m\n",
      "File \u001b[0;32m/home/project-graph-backdoor/Backdoor/models/backdoor.py:340\u001b[0m, in \u001b[0;36mobtain_attach_nodes_by_cluster_gpu\u001b[0;34m(args, y_pred, cluster_centers, node_idxs, x, labels, device, size)\u001b[0m\n\u001b[1;32m    337\u001b[0m single_labels_nodes \u001b[39m=\u001b[39m labels_dict[label]    \u001b[39m# the node idx of the nodes in single class\u001b[39;00m\n\u001b[1;32m    338\u001b[0m single_labels_nodes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(single_labels_nodes)))\n\u001b[0;32m--> 340\u001b[0m single_labels_nodes_dis \u001b[39m=\u001b[39m distances[single_labels_nodes]\n\u001b[1;32m    341\u001b[0m single_labels_nodes_dis \u001b[39m=\u001b[39m max_norm(single_labels_nodes_dis)\n\u001b[1;32m    342\u001b[0m single_labels_nodes_dis_tar \u001b[39m=\u001b[39m distances_tar[single_labels_nodes]\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "# In[9]:\n",
    "\n",
    "from sklearn_extra import cluster\n",
    "from models.backdoor import obtain_attach_nodes,Backdoor, obtain_attach_nodes_by_cluster_gpu,obtain_attach_nodes_by_influential,obtain_attach_nodes_by_cluster\n",
    "\n",
    "from kmeans_pytorch import kmeans, kmeans_predict\n",
    "\n",
    "# filter out the unlabeled nodes except from training nodes and testing nodes, nonzero() is to get index, flatten is to get 1-d tensor\n",
    "unlabeled_idx = (torch.bitwise_not(data.test_mask)&torch.bitwise_not(data.train_mask)).nonzero().flatten()\n",
    "size = int((len(data.test_mask)-data.test_mask.sum())*args.vs_ratio)\n",
    "# here is randomly select poison nodes from unlabeled nodes\n",
    "if(args.selection_method == 'none'):\n",
    "    idx_attach = obtain_attach_nodes(unlabeled_idx,size)\n",
    "elif(args.selection_method == 'loss' or args.selection_method == 'conf'):\n",
    "    idx_attach = obtain_attach_nodes_by_influential(args,benign_model,unlabeled_idx.cpu().tolist(),data.x,train_edge_index,None,data.y,device,size,selected_way=args.selection_method)\n",
    "    idx_attach = torch.LongTensor(idx_attach).to(device)\n",
    "elif(args.selection_method == 'cluster'):\n",
    "    encoder_modelpath = './modelpath/{}_{}_benign.pth'.format('GCN_Encoder', args.dataset)\n",
    "    if(os.path.exists(encoder_modelpath)):\n",
    "        # load existing benign model\n",
    "        gcn_encoder = torch.load(encoder_modelpath)\n",
    "        gcn_encoder = gcn_encoder.to(device)\n",
    "        edge_weights = torch.ones([data.edge_index.shape[1]],device=device,dtype=torch.float)\n",
    "        print(\"Loading {} encoder Finished!\".format(args.model))\n",
    "    else:\n",
    "        gcn_encoder = model_construct(args,'GCN_Encoder',data,device).to(device) \n",
    "        t_total = time.time()\n",
    "        # edge_weights = torch.ones([data.edge_index.shape[1]],device=device,dtype=torch.float)\n",
    "        print(\"Length of training set: {}\".format(len(idx_train)))\n",
    "        gcn_encoder.fit(data.x, train_edge_index, None, data.y, idx_train, idx_val,train_iters=args.epochs,verbose=True)\n",
    "        print(\"Training encoder Finished!\")\n",
    "        print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "        # # Save trained model\n",
    "        # torch.save(gcn_encoder, encoder_modelpath)\n",
    "        # print(\"Encoder saved at {}\".format(encoder_modelpath))\n",
    "    # test gcn encoder \n",
    "    encoder_clean_test_ca = gcn_encoder.test(data.x, data.edge_index, None, data.y,idx_clean_test)\n",
    "    print(\"Encoder CA on clean test nodes: {:.4f}\".format(encoder_clean_test_ca))\n",
    "    # from sklearn import cluster\n",
    "    seen_node_idx = torch.concat([idx_train,unlabeled_idx])\n",
    "    nclass = np.unique(data.y.cpu().numpy()).shape[0]\n",
    "    encoder_x = gcn_encoder.get_h(data.x, train_edge_index,None).clone().detach()\n",
    "    _, cluster_centers = kmeans(X=encoder_x[seen_node_idx], num_clusters=nclass, distance='euclidean', device=device)\n",
    "    # y_pred = kmeans_predict(encoder_x, cluster_centers, 'euclidean', device=device)\n",
    "    encoder_output = gcn_encoder(data.x,train_edge_index,None)\n",
    "    y_pred = np.array(encoder_output.argmax(dim=1).cpu()).astype(int)\n",
    "\n",
    "    idx_attach = obtain_attach_nodes_by_cluster_gpu(args,y_pred,cluster_centers,unlabeled_idx.cpu().tolist(),encoder_x,data.y,device,size).astype(int)\n",
    "    idx_attach = torch.LongTensor(idx_attach).to(device)\n",
    "    # kmedoids = cluster.KMedoids(n_clusters=nclass,method='pam')\n",
    "    # kmedoids.fit(encoder_x[seen_node_idx].detach().cpu().numpy())\n",
    "    # idx_attach = obtain_attach_nodes_by_cluster(args,kmedoids,unlabeled_idx.cpu().tolist(),encoder_x,data.y,device,size)\n",
    "elif(args.selection_method == 'cluster0'):\n",
    "    # construct GCN encoder\n",
    "    encoder_modelpath = './modelpath/{}_{}_benign.pth'.format('GCN_Encoder', args.dataset)\n",
    "    if(os.path.exists(encoder_modelpath)):\n",
    "        # load existing benign model\n",
    "        gcn_encoder = torch.load(encoder_modelpath)\n",
    "        gcn_encoder = gcn_encoder.to(device)\n",
    "        edge_weights = torch.ones([data.edge_index.shape[1]],device=device,dtype=torch.float)\n",
    "        print(\"Loading {} encoder Finished!\".format(args.model))\n",
    "    else:\n",
    "        gcn_encoder = model_construct(args,'GCN_Encoder',data,device).to(device) \n",
    "        t_total = time.time()\n",
    "        # edge_weights = torch.ones([data.edge_index.shape[1]],device=device,dtype=torch.float)\n",
    "        print(\"Length of training set: {}\".format(len(idx_train)))\n",
    "        gcn_encoder.fit(data.x, train_edge_index, None, data.y, idx_train, idx_val,train_iters=args.epochs,verbose=True)\n",
    "        print(\"Training encoder Finished!\")\n",
    "        print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "        # # Save trained model\n",
    "        # torch.save(gcn_encoder, encoder_modelpath)\n",
    "        # print(\"Encoder saved at {}\".format(encoder_modelpath))\n",
    "    # test gcn encoder \n",
    "    encoder_clean_test_ca = gcn_encoder.test(data.x, data.edge_index, None, data.y,idx_clean_test)\n",
    "    print(\"Encoder CA on clean test nodes: {:.4f}\".format(encoder_clean_test_ca))\n",
    "    # from sklearn import cluster\n",
    "    seen_node_idx = torch.concat([idx_train,unlabeled_idx])\n",
    "    nclass = np.unique(data.y.cpu().numpy()).shape[0]\n",
    "    encoder_x = gcn_encoder.get_h(data.x, train_edge_index,None).clone().detach()\n",
    "    gcn_encoder = gcn_encoder.cpu()\n",
    "    kmedoids = cluster.KMedoids(n_clusters=nclass,method='pam')\n",
    "    kmedoids.fit(encoder_x[seen_node_idx].detach().cpu().numpy())\n",
    "    idx_attach = obtain_attach_nodes_by_cluster(args,kmedoids,unlabeled_idx.cpu().tolist(),encoder_x,data.y,device,size).astype(int)\n",
    "    idx_attach = torch.LongTensor(idx_attach).to(device)\n",
    "\n",
    "# In[10]:\n",
    "# train trigger generator \n",
    "model = Backdoor(args,device)\n",
    "if(args.attack_method == 'Basic'):\n",
    "    model.fit(data.x, train_edge_index, None, data.y, idx_train,idx_attach, unlabeled_idx)\n",
    "    poison_x, poison_edge_index, poison_edge_weights, poison_labels = model.get_poisoned()\n",
    "elif(args.attack_method == 'Rand_Gene' or args.attack_method == 'Rand_Samp'):\n",
    "    model.fit_rand(data.x, train_edge_index, None, data.y, idx_train,idx_attach, unlabeled_idx)\n",
    "    poison_x, poison_edge_index, poison_edge_weights, poison_labels = model.get_poisoned_rand()\n",
    "elif(args.attack_method == 'None'):\n",
    "    train_edge_weights = torch.ones([train_edge_index.shape[1]],device=device,dtype=torch.float)\n",
    "    poison_x, poison_edge_index, poison_edge_weights, poison_labels = data.x.clone(), train_edge_index.clone(), train_edge_weights, data.y.clone()\n",
    "\n",
    "# In[12]:\n",
    "if(args.defense_mode == 'prune'):\n",
    "    poison_edge_index,poison_edge_weights = prune_unrelated_edge(args,poison_edge_index,poison_edge_weights,poison_x,device)\n",
    "    bkd_tn_nodes = torch.cat([idx_train,idx_attach]).to(device)\n",
    "elif(args.defense_mode == 'isolate'):\n",
    "    poison_edge_index,poison_edge_weights,rel_nodes = prune_unrelated_edge_isolated(args,poison_edge_index,poison_edge_weights,poison_x,device)\n",
    "    bkd_tn_nodes = torch.cat([idx_train,idx_attach]).tolist()\n",
    "    bkd_tn_nodes = torch.LongTensor(list(set(bkd_tn_nodes) - set(rel_nodes))).to(device)\n",
    "else:\n",
    "    bkd_tn_nodes = torch.cat([idx_train,idx_attach]).to(device)\n",
    "\n",
    "print(\"precent of left attach nodes: {:.3f}\"\\\n",
    "    .format(len(set(bkd_tn_nodes.tolist()) & set(idx_attach.tolist()))/len(idx_attach)))\n",
    "#%%\n",
    "test_model = model_construct(args,args.test_model,data,device).to(device) \n",
    "test_model.fit(poison_x, poison_edge_index, poison_edge_weights, poison_labels, bkd_tn_nodes, idx_val,train_iters=args.epochs,verbose=False)\n",
    "\n",
    "output = test_model(poison_x,poison_edge_index,poison_edge_weights)\n",
    "train_attach_rate = (output.argmax(dim=1)[idx_attach]==args.target_class).float().mean()\n",
    "print(\"target class rate on Vs: {:.4f}\".format(train_attach_rate))\n",
    "#%%\n",
    "induct_edge_index = torch.cat([poison_edge_index,mask_edge_index],dim=1)\n",
    "induct_edge_weights = torch.cat([poison_edge_weights,torch.ones([mask_edge_index.shape[1]],dtype=torch.float,device=device)])\n",
    "clean_acc = test_model.test(poison_x,induct_edge_index,induct_edge_weights,data.y,idx_clean_test)\n",
    "# test_model = test_model.cpu()\n",
    "\n",
    "print(\"accuracy on clean test nodes: {:.4f}\".format(clean_acc))\n",
    "\n",
    "# poison_x, poison_edge_index, poison_edge_weights, poison_labels = poison_x.to(device2), poison_edge_index.to(device2), poison_edge_weights.to(device2), poison_labels.to(device2)\n",
    "# model.trojan = model.trojan.cpu()\n",
    "# %% inject trigger on attack test nodes (idx_atk)'''\n",
    "if(args.attack_method == 'Basic'):\n",
    "    induct_x, induct_edge_index,induct_edge_weights = model.inject_trigger(idx_atk,poison_x,induct_edge_index,induct_edge_weights,device)\n",
    "elif(args.attack_method == 'Rand_Gene' or args.attack_method == 'Rand_Samp'):\n",
    "    induct_x, induct_edge_index,induct_edge_weights = model.inject_trigger_rand(idx_atk,poison_x,induct_edge_index,induct_edge_weights,data.y)\n",
    "elif(args.attack_method == 'None'):\n",
    "    induct_x, induct_edge_index,induct_edge_weights = poison_x,induct_edge_index,induct_edge_weights\n",
    "# do pruning in test datas'''\n",
    "if(args.defense_mode == 'prune' or args.defense_mode == 'isolate'):\n",
    "    induct_edge_index,induct_edge_weights = prune_unrelated_edge(args,induct_edge_index,induct_edge_weights,induct_x,device)\n",
    "# attack evaluation\n",
    "\n",
    "# test_model = test_model.to(device)\n",
    "output = test_model(induct_x,induct_edge_index,induct_edge_weights)\n",
    "train_attach_rate = (output.argmax(dim=1)[idx_atk]==args.target_class).float().mean()\n",
    "print(\"ASR: {:.4f}\".format(train_attach_rate))\n",
    "ca = test_model.test(induct_x,induct_edge_index,induct_edge_weights,data.y,idx_clean_test)\n",
    "print(\"CA: {:.4f}\".format(ca))\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 28, 28, ..., 30, 24,  8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 106.83 GiB (GPU 0; 47.54 GiB total capacity; 1.10 GiB already allocated; 45.23 GiB free; 1.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/project-graph-backdoor/Backdoor/run.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_dense_adj\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m poison_adj_dense \u001b[39m=\u001b[39m to_dense_adj(poison_edge_index)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39medge_sim_analysis\u001b[39m(edge_index, features):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bszw494-root/home/project-graph-backdoor/Backdoor/run.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     sims \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/py38_torch110/lib/python3.8/site-packages/torch_geometric/utils/to_dense_adj.py:48\u001b[0m, in \u001b[0;36mto_dense_adj\u001b[0;34m(edge_index, batch, edge_attr, max_num_nodes)\u001b[0m\n\u001b[1;32m     46\u001b[0m size \u001b[39m=\u001b[39m [batch_size, max_num_nodes, max_num_nodes]\n\u001b[1;32m     47\u001b[0m size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(edge_attr\u001b[39m.\u001b[39msize())[\u001b[39m1\u001b[39m:]\n\u001b[0;32m---> 48\u001b[0m adj \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(size, dtype\u001b[39m=\u001b[39;49medge_attr\u001b[39m.\u001b[39;49mdtype, device\u001b[39m=\u001b[39;49medge_index\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     50\u001b[0m flattened_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m max_num_nodes \u001b[39m*\u001b[39m max_num_nodes\n\u001b[1;32m     51\u001b[0m adj \u001b[39m=\u001b[39m adj\u001b[39m.\u001b[39mview([flattened_size] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(adj\u001b[39m.\u001b[39msize())[\u001b[39m3\u001b[39m:])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 106.83 GiB (GPU 0; 47.54 GiB total capacity; 1.10 GiB already allocated; 45.23 GiB free; 1.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "poison_adj_dense = to_dense_adj(poison_edge_index)\n",
    "def edge_sim_analysis(edge_index, features):\n",
    "    sims = []\n",
    "    for (u,v) in edge_index:\n",
    "        sims.append(float(F.cosine_similarity(features[u].unsqueeze(0),features[v].unsqueeze(0))))\n",
    "    sims = np.array(sims)\n",
    "    # print(f\"mean: {sims.mean()}, <0.1: {sum(sims<0.1)}/{sims.shape[0]}\")\n",
    "    return sims\n",
    "\n",
    "bkd_nids = list(range(data.x.shape[0],poison_x.shape[0]))\n",
    "for nid in idx_attach:\n",
    "    # polished_dr_test = copy.deepcopy(bkd_dr_test)\n",
    "    # polished_adj_nodes = polished_dr_test.data['mat_adj'].to_dense()[nid].nonzero()\n",
    "    polished_adj_nodes = poison_adj_dense[0][nid].nonzero()\n",
    "    # bkd_nids = list(range(poison_x.shape[0],induct_x.shape[0]))\n",
    "    for v in polished_adj_nodes:\n",
    "        v = int(v)\n",
    "        if(v in bkd_nids):\n",
    "            u = nid\n",
    "            print(nid,v)\n",
    "            print(F.cosine_similarity(poison_x[u].unsqueeze(0),poison_x[v].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_torch110')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4260eba67904b42d68a3963bc583366103d86fb6c89846e20de6072b78e7707"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
