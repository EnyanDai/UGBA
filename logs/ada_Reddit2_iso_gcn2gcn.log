nohup: ignoring input
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
1
2
Namespace(attack_method='Basic', cuda=True, dataset='Reddit2', debug=True, defense_mode='isolate', device_id=2, dis_weight=1.0, dropout=0.5, epochs=200, hidden=128, homo_boost_thrd=0.5, homo_loss_weight=1.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.2, seed=10, selection_method='cluster', target_class=0, target_loss_weight=1, test_model='GCN', thrd=0.5, train_lr=0.02, trigger_prob=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.3497
Length of training set: 46593
=== training gcn model ===
Epoch 0, training loss: 3.716425657272339
acc_val: 0.0479
Epoch 10, training loss: 3.406393527984619
acc_val: 0.1268
Epoch 20, training loss: 3.125899314880371
acc_val: 0.1518
Epoch 30, training loss: 2.947032928466797
acc_val: 0.2123
Epoch 40, training loss: 2.8642385005950928
acc_val: 0.2357
Epoch 50, training loss: 2.667708396911621
acc_val: 0.3147
Epoch 60, training loss: 2.3649559020996094
acc_val: 0.3834
Epoch 70, training loss: 2.1966052055358887
acc_val: 0.4445
Epoch 80, training loss: 2.0941545963287354
acc_val: 0.4639
Epoch 90, training loss: 2.030958890914917
acc_val: 0.4735
Epoch 100, training loss: 1.9978628158569336
acc_val: 0.4765
Epoch 110, training loss: 1.9599343538284302
acc_val: 0.4844
Epoch 120, training loss: 1.9412983655929565
acc_val: 0.4927
Epoch 130, training loss: 1.9242912530899048
acc_val: 0.4953
Epoch 140, training loss: 1.907820224761963
acc_val: 0.4957
Epoch 150, training loss: 1.8976420164108276
acc_val: 0.5018
Epoch 160, training loss: 1.882531762123108
acc_val: 0.5027
Epoch 170, training loss: 1.8774019479751587
acc_val: 0.5088
Epoch 180, training loss: 1.8791284561157227
acc_val: 0.5043
Epoch 190, training loss: 1.864327311515808
acc_val: 0.5070
=== picking the best model according to the performance on validation ===
Training encoder Finished!
Total time elapsed: 95.1991s
Encoder CA on clean test nodes: 0.5092
running k-means on cuda:2..
[running kmeans]: 0it [00:00, ?it/s][running kmeans]: 0it [00:01, ?it/s, center_shift=736.461121, iteration=1, tol=0.000100][running kmeans]: 1it [00:01,  1.23s/it, center_shift=736.461121, iteration=1, tol=0.000100][running kmeans]: 1it [00:02,  1.23s/it, center_shift=176.353424, iteration=2, tol=0.000100][running kmeans]: 2it [00:02,  1.27s/it, center_shift=176.353424, iteration=2, tol=0.000100][running kmeans]: 2it [00:03,  1.27s/it, center_shift=69.408630, iteration=3, tol=0.000100] [running kmeans]: 3it [00:03,  1.30s/it, center_shift=69.408630, iteration=3, tol=0.000100][running kmeans]: 3it [00:05,  1.30s/it, center_shift=47.760204, iteration=4, tol=0.000100][running kmeans]: 4it [00:05,  1.29s/it, center_shift=47.760204, iteration=4, tol=0.000100][running kmeans]: 4it [00:06,  1.29s/it, center_shift=36.434116, iteration=5, tol=0.000100][running kmeans]: 5it [00:06,  1.29s/it, center_shift=36.434116, iteration=5, tol=0.000100][running kmeans]: 5it [00:07,  1.29s/it, center_shift=28.870197, iteration=6, tol=0.000100][running kmeans]: 6it [00:07,  1.36s/it, center_shift=28.870197, iteration=6, tol=0.000100][running kmeans]: 6it [00:09,  1.36s/it, center_shift=25.819153, iteration=7, tol=0.000100][running kmeans]: 7it [00:09,  1.35s/it, center_shift=25.819153, iteration=7, tol=0.000100][running kmeans]: 7it [00:10,  1.35s/it, center_shift=23.516150, iteration=8, tol=0.000100][running kmeans]: 8it [00:10,  1.37s/it, center_shift=23.516150, iteration=8, tol=0.000100][running kmeans]: 8it [00:12,  1.37s/it, center_shift=20.963594, iteration=9, tol=0.000100][running kmeans]: 9it [00:12,  1.42s/it, center_shift=20.963594, iteration=9, tol=0.000100][running kmeans]: 9it [00:13,  1.42s/it, center_shift=15.981367, iteration=10, tol=0.000100][running kmeans]: 10it [00:13,  1.37s/it, center_shift=15.981367, iteration=10, tol=0.000100][running kmeans]: 10it [00:14,  1.37s/it, center_shift=9.908470, iteration=11, tol=0.000100] [running kmeans]: 11it [00:14,  1.38s/it, center_shift=9.908470, iteration=11, tol=0.000100][running kmeans]: 11it [00:16,  1.38s/it, center_shift=7.254716, iteration=12, tol=0.000100][running kmeans]: 12it [00:16,  1.35s/it, center_shift=7.254716, iteration=12, tol=0.000100][running kmeans]: 12it [00:17,  1.35s/it, center_shift=5.959986, iteration=13, tol=0.000100][running kmeans]: 13it [00:17,  1.41s/it, center_shift=5.959986, iteration=13, tol=0.000100][running kmeans]: 13it [00:18,  1.41s/it, center_shift=4.516566, iteration=14, tol=0.000100][running kmeans]: 14it [00:18,  1.35s/it, center_shift=4.516566, iteration=14, tol=0.000100][running kmeans]: 14it [00:20,  1.35s/it, center_shift=3.330527, iteration=15, tol=0.000100][running kmeans]: 15it [00:20,  1.34s/it, center_shift=3.330527, iteration=15, tol=0.000100][running kmeans]: 15it [00:21,  1.34s/it, center_shift=2.885445, iteration=16, tol=0.000100][running kmeans]: 16it [00:21,  1.34s/it, center_shift=2.885445, iteration=16, tol=0.000100][running kmeans]: 16it [00:23,  1.34s/it, center_shift=2.326999, iteration=17, tol=0.000100][running kmeans]: 17it [00:23,  1.40s/it, center_shift=2.326999, iteration=17, tol=0.000100][running kmeans]: 17it [00:24,  1.40s/it, center_shift=2.153589, iteration=18, tol=0.000100][running kmeans]: 18it [00:24,  1.40s/it, center_shift=2.153589, iteration=18, tol=0.000100][running kmeans]: 18it [00:25,  1.40s/it, center_shift=2.056019, iteration=19, tol=0.000100][running kmeans]: 19it [00:25,  1.38s/it, center_shift=2.056019, iteration=19, tol=0.000100][running kmeans]: 19it [00:27,  1.38s/it, center_shift=1.896739, iteration=20, tol=0.000100][running kmeans]: 20it [00:27,  1.40s/it, center_shift=1.896739, iteration=20, tol=0.000100][running kmeans]: 20it [00:28,  1.40s/it, center_shift=1.608270, iteration=21, tol=0.000100][running kmeans]: 21it [00:28,  1.32s/it, center_shift=1.608270, iteration=21, tol=0.000100][running kmeans]: 21it [00:29,  1.32s/it, center_shift=1.525876, iteration=22, tol=0.000100][running kmeans]: 22it [00:29,  1.34s/it, center_shift=1.525876, iteration=22, tol=0.000100][running kmeans]: 22it [00:31,  1.34s/it, center_shift=1.333903, iteration=23, tol=0.000100][running kmeans]: 23it [00:31,  1.41s/it, center_shift=1.333903, iteration=23, tol=0.000100][running kmeans]: 23it [00:32,  1.41s/it, center_shift=1.001665, iteration=24, tol=0.000100][running kmeans]: 24it [00:32,  1.44s/it, center_shift=1.001665, iteration=24, tol=0.000100][running kmeans]: 24it [00:34,  1.44s/it, center_shift=0.869868, iteration=25, tol=0.000100][running kmeans]: 25it [00:34,  1.43s/it, center_shift=0.869868, iteration=25, tol=0.000100][running kmeans]: 25it [00:35,  1.43s/it, center_shift=0.766331, iteration=26, tol=0.000100][running kmeans]: 26it [00:35,  1.43s/it, center_shift=0.766331, iteration=26, tol=0.000100][running kmeans]: 26it [00:37,  1.43s/it, center_shift=0.668657, iteration=27, tol=0.000100][running kmeans]: 27it [00:37,  1.38s/it, center_shift=0.668657, iteration=27, tol=0.000100][running kmeans]: 27it [00:38,  1.38s/it, center_shift=0.522699, iteration=28, tol=0.000100][running kmeans]: 28it [00:38,  1.41s/it, center_shift=0.522699, iteration=28, tol=0.000100][running kmeans]: 28it [00:39,  1.41s/it, center_shift=0.549463, iteration=29, tol=0.000100][running kmeans]: 29it [00:39,  1.36s/it, center_shift=0.549463, iteration=29, tol=0.000100][running kmeans]: 29it [00:41,  1.36s/it, center_shift=0.497789, iteration=30, tol=0.000100][running kmeans]: 30it [00:41,  1.45s/it, center_shift=0.497789, iteration=30, tol=0.000100][running kmeans]: 30it [00:42,  1.45s/it, center_shift=0.383308, iteration=31, tol=0.000100][running kmeans]: 31it [00:42,  1.37s/it, center_shift=0.383308, iteration=31, tol=0.000100][running kmeans]: 31it [00:44,  1.37s/it, center_shift=0.320841, iteration=32, tol=0.000100][running kmeans]: 32it [00:44,  1.44s/it, center_shift=0.320841, iteration=32, tol=0.000100][running kmeans]: 32it [00:45,  1.44s/it, center_shift=0.340236, iteration=33, tol=0.000100][running kmeans]: 33it [00:45,  1.37s/it, center_shift=0.340236, iteration=33, tol=0.000100][running kmeans]: 33it [00:46,  1.37s/it, center_shift=0.317679, iteration=34, tol=0.000100][running kmeans]: 34it [00:46,  1.30s/it, center_shift=0.317679, iteration=34, tol=0.000100][running kmeans]: 34it [00:47,  1.30s/it, center_shift=0.333166, iteration=35, tol=0.000100][running kmeans]: 35it [00:47,  1.27s/it, center_shift=0.333166, iteration=35, tol=0.000100][running kmeans]: 35it [00:48,  1.27s/it, center_shift=0.263455, iteration=36, tol=0.000100][running kmeans]: 36it [00:48,  1.26s/it, center_shift=0.263455, iteration=36, tol=0.000100][running kmeans]: 36it [00:50,  1.26s/it, center_shift=0.242430, iteration=37, tol=0.000100][running kmeans]: 37it [00:50,  1.31s/it, center_shift=0.242430, iteration=37, tol=0.000100][running kmeans]: 37it [00:51,  1.31s/it, center_shift=0.231310, iteration=38, tol=0.000100][running kmeans]: 38it [00:51,  1.29s/it, center_shift=0.231310, iteration=38, tol=0.000100][running kmeans]: 38it [00:52,  1.29s/it, center_shift=0.295391, iteration=39, tol=0.000100][running kmeans]: 39it [00:52,  1.29s/it, center_shift=0.295391, iteration=39, tol=0.000100][running kmeans]: 39it [00:54,  1.29s/it, center_shift=0.314273, iteration=40, tol=0.000100][running kmeans]: 40it [00:54,  1.32s/it, center_shift=0.314273, iteration=40, tol=0.000100][running kmeans]: 40it [00:55,  1.32s/it, center_shift=0.372911, iteration=41, tol=0.000100][running kmeans]: 41it [00:55,  1.36s/it, center_shift=0.372911, iteration=41, tol=0.000100][running kmeans]: 41it [00:57,  1.36s/it, center_shift=0.323169, iteration=42, tol=0.000100][running kmeans]: 42it [00:57,  1.38s/it, center_shift=0.323169, iteration=42, tol=0.000100][running kmeans]: 42it [00:58,  1.38s/it, center_shift=0.362364, iteration=43, tol=0.000100][running kmeans]: 43it [00:58,  1.33s/it, center_shift=0.362364, iteration=43, tol=0.000100][running kmeans]: 43it [00:59,  1.33s/it, center_shift=0.374471, iteration=44, tol=0.000100][running kmeans]: 44it [00:59,  1.40s/it, center_shift=0.374471, iteration=44, tol=0.000100][running kmeans]: 44it [01:01,  1.40s/it, center_shift=0.400143, iteration=45, tol=0.000100][running kmeans]: 45it [01:01,  1.36s/it, center_shift=0.400143, iteration=45, tol=0.000100][running kmeans]: 45it [01:02,  1.36s/it, center_shift=0.528373, iteration=46, tol=0.000100][running kmeans]: 46it [01:02,  1.38s/it, center_shift=0.528373, iteration=46, tol=0.000100][running kmeans]: 46it [01:03,  1.38s/it, center_shift=0.476150, iteration=47, tol=0.000100][running kmeans]: 47it [01:03,  1.33s/it, center_shift=0.476150, iteration=47, tol=0.000100][running kmeans]: 47it [01:05,  1.33s/it, center_shift=0.440890, iteration=48, tol=0.000100][running kmeans]: 48it [01:05,  1.35s/it, center_shift=0.440890, iteration=48, tol=0.000100][running kmeans]: 48it [01:06,  1.35s/it, center_shift=0.515703, iteration=49, tol=0.000100][running kmeans]: 49it [01:06,  1.29s/it, center_shift=0.515703, iteration=49, tol=0.000100][running kmeans]: 49it [01:07,  1.29s/it, center_shift=0.402091, iteration=50, tol=0.000100][running kmeans]: 50it [01:07,  1.33s/it, center_shift=0.402091, iteration=50, tol=0.000100][running kmeans]: 50it [01:09,  1.33s/it, center_shift=0.382205, iteration=51, tol=0.000100][running kmeans]: 51it [01:09,  1.39s/it, center_shift=0.382205, iteration=51, tol=0.000100][running kmeans]: 51it [01:10,  1.39s/it, center_shift=0.386261, iteration=52, tol=0.000100][running kmeans]: 52it [01:10,  1.38s/it, center_shift=0.386261, iteration=52, tol=0.000100][running kmeans]: 52it [01:12,  1.38s/it, center_shift=0.294392, iteration=53, tol=0.000100][running kmeans]: 53it [01:12,  1.36s/it, center_shift=0.294392, iteration=53, tol=0.000100][running kmeans]: 53it [01:13,  1.36s/it, center_shift=0.262077, iteration=54, tol=0.000100][running kmeans]: 54it [01:13,  1.42s/it, center_shift=0.262077, iteration=54, tol=0.000100][running kmeans]: 54it [01:15,  1.42s/it, center_shift=0.163114, iteration=55, tol=0.000100][running kmeans]: 55it [01:15,  1.47s/it, center_shift=0.163114, iteration=55, tol=0.000100][running kmeans]: 55it [01:16,  1.47s/it, center_shift=0.158298, iteration=56, tol=0.000100][running kmeans]: 56it [01:16,  1.41s/it, center_shift=0.158298, iteration=56, tol=0.000100][running kmeans]: 56it [01:17,  1.41s/it, center_shift=0.143601, iteration=57, tol=0.000100][running kmeans]: 57it [01:17,  1.37s/it, center_shift=0.143601, iteration=57, tol=0.000100][running kmeans]: 57it [01:18,  1.37s/it, center_shift=0.122410, iteration=58, tol=0.000100][running kmeans]: 58it [01:18,  1.28s/it, center_shift=0.122410, iteration=58, tol=0.000100][running kmeans]: 58it [01:20,  1.28s/it, center_shift=0.113982, iteration=59, tol=0.000100][running kmeans]: 59it [01:20,  1.27s/it, center_shift=0.113982, iteration=59, tol=0.000100][running kmeans]: 59it [01:21,  1.27s/it, center_shift=0.070772, iteration=60, tol=0.000100][running kmeans]: 60it [01:21,  1.37s/it, center_shift=0.070772, iteration=60, tol=0.000100][running kmeans]: 60it [01:23,  1.37s/it, center_shift=0.057010, iteration=61, tol=0.000100][running kmeans]: 61it [01:23,  1.37s/it, center_shift=0.057010, iteration=61, tol=0.000100][running kmeans]: 61it [01:24,  1.37s/it, center_shift=0.055622, iteration=62, tol=0.000100][running kmeans]: 62it [01:24,  1.36s/it, center_shift=0.055622, iteration=62, tol=0.000100][running kmeans]: 62it [01:25,  1.36s/it, center_shift=0.048121, iteration=63, tol=0.000100][running kmeans]: 63it [01:25,  1.32s/it, center_shift=0.048121, iteration=63, tol=0.000100][running kmeans]: 63it [01:26,  1.32s/it, center_shift=0.033544, iteration=64, tol=0.000100][running kmeans]: 64it [01:26,  1.31s/it, center_shift=0.033544, iteration=64, tol=0.000100][running kmeans]: 64it [01:28,  1.31s/it, center_shift=0.021976, iteration=65, tol=0.000100][running kmeans]: 65it [01:28,  1.31s/it, center_shift=0.021976, iteration=65, tol=0.000100][running kmeans]: 65it [01:29,  1.31s/it, center_shift=0.020053, iteration=66, tol=0.000100][running kmeans]: 66it [01:29,  1.31s/it, center_shift=0.020053, iteration=66, tol=0.000100][running kmeans]: 66it [01:30,  1.31s/it, center_shift=0.009603, iteration=67, tol=0.000100][running kmeans]: 67it [01:30,  1.35s/it, center_shift=0.009603, iteration=67, tol=0.000100][running kmeans]: 67it [01:32,  1.35s/it, center_shift=0.008695, iteration=68, tol=0.000100][running kmeans]: 68it [01:32,  1.40s/it, center_shift=0.008695, iteration=68, tol=0.000100][running kmeans]: 68it [01:33,  1.40s/it, center_shift=0.007370, iteration=69, tol=0.000100][running kmeans]: 69it [01:33,  1.36s/it, center_shift=0.007370, iteration=69, tol=0.000100][running kmeans]: 69it [01:35,  1.36s/it, center_shift=0.006146, iteration=70, tol=0.000100][running kmeans]: 70it [01:35,  1.38s/it, center_shift=0.006146, iteration=70, tol=0.000100][running kmeans]: 70it [01:36,  1.38s/it, center_shift=0.004932, iteration=71, tol=0.000100][running kmeans]: 71it [01:36,  1.37s/it, center_shift=0.004932, iteration=71, tol=0.000100][running kmeans]: 71it [01:37,  1.37s/it, center_shift=0.002678, iteration=72, tol=0.000100][running kmeans]: 72it [01:37,  1.33s/it, center_shift=0.002678, iteration=72, tol=0.000100][running kmeans]: 72it [01:38,  1.33s/it, center_shift=0.002598, iteration=73, tol=0.000100][running kmeans]: 73it [01:38,  1.27s/it, center_shift=0.002598, iteration=73, tol=0.000100][running kmeans]: 73it [01:39,  1.27s/it, center_shift=0.002336, iteration=74, tol=0.000100][running kmeans]: 74it [01:39,  1.22s/it, center_shift=0.002336, iteration=74, tol=0.000100][running kmeans]: 74it [01:41,  1.22s/it, center_shift=0.001615, iteration=75, tol=0.000100][running kmeans]: 75it [01:41,  1.36s/it, center_shift=0.001615, iteration=75, tol=0.000100][running kmeans]: 75it [01:42,  1.36s/it, center_shift=0.001055, iteration=76, tol=0.000100][running kmeans]: 76it [01:42,  1.30s/it, center_shift=0.001055, iteration=76, tol=0.000100][running kmeans]: 76it [01:44,  1.30s/it, center_shift=0.000565, iteration=77, tol=0.000100][running kmeans]: 77it [01:44,  1.31s/it, center_shift=0.000565, iteration=77, tol=0.000100][running kmeans]: 77it [01:45,  1.31s/it, center_shift=0.000466, iteration=78, tol=0.000100][running kmeans]: 78it [01:45,  1.26s/it, center_shift=0.000466, iteration=78, tol=0.000100][running kmeans]: 78it [01:46,  1.26s/it, center_shift=0.000463, iteration=79, tol=0.000100][running kmeans]: 79it [01:46,  1.26s/it, center_shift=0.000463, iteration=79, tol=0.000100][running kmeans]: 79it [01:47,  1.26s/it, center_shift=0.000202, iteration=80, tol=0.000100][running kmeans]: 80it [01:47,  1.24s/it, center_shift=0.000202, iteration=80, tol=0.000100][running kmeans]: 80it [01:49,  1.24s/it, center_shift=0.000168, iteration=81, tol=0.000100][running kmeans]: 81it [01:49,  1.28s/it, center_shift=0.000168, iteration=81, tol=0.000100][running kmeans]: 81it [01:50,  1.28s/it, center_shift=0.000281, iteration=82, tol=0.000100][running kmeans]: 82it [01:50,  1.34s/it, center_shift=0.000281, iteration=82, tol=0.000100][running kmeans]: 82it [01:52,  1.34s/it, center_shift=0.000263, iteration=83, tol=0.000100][running kmeans]: 83it [01:52,  1.41s/it, center_shift=0.000263, iteration=83, tol=0.000100][running kmeans]: 83it [01:53,  1.41s/it, center_shift=0.000111, iteration=84, tol=0.000100][running kmeans]: 84it [01:53,  1.35s/it, center_shift=0.000111, iteration=84, tol=0.000100][running kmeans]: 84it [01:55,  1.35s/it, center_shift=0.000048, iteration=85, tol=0.000100][running kmeans]: 85it [01:55,  1.43s/it, center_shift=0.000048, iteration=85, tol=0.000100][running kmeans]: 85it [01:55,  1.35s/it, center_shift=0.000048, iteration=85, tol=0.000100]
predicting on cuda:2..
tensor([25,  9,  5,  ..., 14,  2,  6])
Traceback (most recent call last):
  File "run.py", line 258, in <module>
    model.fit(data.x, train_edge_index, None, data.y, idx_train,idx_attach, unlabeled_idx)
  File "/home/project-graph-backdoor/Backdoor/models/backdoor.py", line 464, in fit
    loss_inner.backward()
  File "/root/anaconda3/envs/py38_torch110/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/root/anaconda3/envs/py38_torch110/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 7.21 GiB (GPU 2; 47.54 GiB total capacity; 26.09 GiB already allocated; 4.06 GiB free; 39.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
