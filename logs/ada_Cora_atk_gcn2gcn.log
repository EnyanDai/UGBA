nohup: ignoring input
Namespace(attack_method='GTA', cuda=True, dataset='Cora', debug=True, defense_mode='none', device_id=1, dis_weight=1, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.5, homo_loss_weight=1.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.3, seed=10, selection_method='cluster', target_class=0, target_loss_weight=1, test_model='GCN', thrd=0.5, trigger_prob=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Length of training set: 541
Training benign model Finished!
Total time elapsed: 2.6546s
Benign CA: 0.8444
Length of training set: 541
=== training gcn model ===
Epoch 0, training loss: 1.9322519302368164
acc_val: 0.2926
Epoch 10, training loss: 1.8021061420440674
acc_val: 0.3037
Epoch 20, training loss: 1.7138646841049194
acc_val: 0.3037
Epoch 30, training loss: 1.4916402101516724
acc_val: 0.3704
Epoch 40, training loss: 1.2497543096542358
acc_val: 0.4222
Epoch 50, training loss: 1.079182505607605
acc_val: 0.4852
Epoch 60, training loss: 0.9507980942726135
acc_val: 0.5519
Epoch 70, training loss: 0.8186353445053101
acc_val: 0.5889
Epoch 80, training loss: 0.7561426162719727
acc_val: 0.6037
Epoch 90, training loss: 0.7051458358764648
acc_val: 0.6815
Epoch 100, training loss: 0.6418095827102661
acc_val: 0.7037
Epoch 110, training loss: 0.5879091620445251
acc_val: 0.6963
Epoch 120, training loss: 0.5704083442687988
acc_val: 0.7074
Epoch 130, training loss: 0.538766086101532
acc_val: 0.7222
Epoch 140, training loss: 0.5040132403373718
acc_val: 0.7074
Epoch 150, training loss: 0.49455180764198303
acc_val: 0.7148
Epoch 160, training loss: 0.4650726914405823
acc_val: 0.7111
Epoch 170, training loss: 0.42495280504226685
acc_val: 0.7185
Epoch 180, training loss: 0.42690137028694153
acc_val: 0.7111
Epoch 190, training loss: 0.3947491943836212
acc_val: 0.7333
=== picking the best model according to the performance on validation ===
Training encoder Finished!
Total time elapsed: 1.9569s
Encoder CA on clean test nodes: 0.7926
[1 3 3 ... 5 1 1]
Epoch 0, loss_inner: 1.94553, loss_target: 1.90072, homo loss: 0.50863 
acc_train_clean: 0.2126, ASR_train_attach: 0.0000, ASR_train_outter: 0.7505
Epoch 10, loss_inner: 1.69405, loss_target: 1.09916, homo loss: 0.48243 
acc_train_clean: 0.3161, ASR_train_attach: 1.0000, ASR_train_outter: 0.9962
Epoch 20, loss_inner: 1.55734, loss_target: 1.02389, homo loss: 0.46621 
acc_train_clean: 0.3179, ASR_train_attach: 1.0000, ASR_train_outter: 0.9775
Epoch 30, loss_inner: 1.67871, loss_target: 1.88960, homo loss: 0.41263 
acc_train_clean: 0.4603, ASR_train_attach: 0.3333, ASR_train_outter: 1.0000
Epoch 40, loss_inner: 1.67090, loss_target: 1.38373, homo loss: 0.16186 
acc_train_clean: 0.5545, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 50, loss_inner: 1.45154, loss_target: 0.83733, homo loss: 0.17283 
acc_train_clean: 0.4104, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 60, loss_inner: 1.35708, loss_target: 0.63542, homo loss: 0.15873 
acc_train_clean: 0.5176, ASR_train_attach: 1.0000, ASR_train_outter: 0.9962
Epoch 70, loss_inner: 1.23225, loss_target: 0.51351, homo loss: 0.14281 
acc_train_clean: 0.6599, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 80, loss_inner: 1.10542, loss_target: 0.44074, homo loss: 0.12598 
acc_train_clean: 0.7320, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 90, loss_inner: 0.98392, loss_target: 0.40947, homo loss: 0.11021 
acc_train_clean: 0.7708, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 100, loss_inner: 0.87330, loss_target: 0.35654, homo loss: 0.10244 
acc_train_clean: 0.8115, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 110, loss_inner: 0.78449, loss_target: 0.34207, homo loss: 0.09894 
acc_train_clean: 0.8392, ASR_train_attach: 1.0000, ASR_train_outter: 0.9944
Epoch 120, loss_inner: 0.70963, loss_target: 0.29343, homo loss: 0.10206 
acc_train_clean: 0.8632, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 130, loss_inner: 0.64941, loss_target: 0.29325, homo loss: 0.10549 
acc_train_clean: 0.8706, ASR_train_attach: 1.0000, ASR_train_outter: 0.9962
Epoch 140, loss_inner: 0.60080, loss_target: 0.25487, homo loss: 0.10395 
acc_train_clean: 0.8725, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 150, loss_inner: 0.57928, loss_target: 0.47371, homo loss: 0.11292 
acc_train_clean: 0.8725, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 160, loss_inner: 0.54224, loss_target: 0.28304, homo loss: 0.13563 
acc_train_clean: 0.8799, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 170, loss_inner: 0.51341, loss_target: 0.23597, homo loss: 0.13274 
acc_train_clean: 0.8854, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 180, loss_inner: 0.48520, loss_target: 0.23477, homo loss: 0.11833 
acc_train_clean: 0.9002, ASR_train_attach: 1.0000, ASR_train_outter: 0.9944
Epoch 190, loss_inner: 0.47610, loss_target: 0.29192, homo loss: 0.14792 
acc_train_clean: 0.8946, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
precent of left attach nodes: 1.000
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.8333
ASR: 1.0000
CA: 0.8296
