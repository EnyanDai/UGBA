nohup: ignoring input
Namespace(cuda=True, dataset='Cora', debug=True, defense_mode='none', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.5, homo_loss_weight=1.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.3, seed=10, selection_method='cluster', target_class=0, test_model='GCN', thrd=0.0, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Length of training set: 541
Training benign model Finished!
Total time elapsed: 12.5037s
Benign CA: 0.8444
Length of training set: 541
=== training gcn model ===
Epoch 0, training loss: 1.9322519302368164
acc_val: 0.2926
Epoch 10, training loss: 1.8021061420440674
acc_val: 0.3037
Epoch 20, training loss: 1.713864803314209
acc_val: 0.3037
Epoch 30, training loss: 1.4916369915008545
acc_val: 0.3704
Epoch 40, training loss: 1.249752402305603
acc_val: 0.4222
Epoch 50, training loss: 1.079205870628357
acc_val: 0.4852
Epoch 60, training loss: 0.9508324861526489
acc_val: 0.5519
Epoch 70, training loss: 0.8185818791389465
acc_val: 0.5889
Epoch 80, training loss: 0.7560439109802246
acc_val: 0.6000
Epoch 90, training loss: 0.7048591375350952
acc_val: 0.6815
Epoch 100, training loss: 0.641007125377655
acc_val: 0.7037
Epoch 110, training loss: 0.5871880054473877
acc_val: 0.7000
Epoch 120, training loss: 0.5697429776191711
acc_val: 0.7074
Epoch 130, training loss: 0.5388628840446472
acc_val: 0.7222
Epoch 140, training loss: 0.5049092769622803
acc_val: 0.7185
Epoch 150, training loss: 0.49566566944122314
acc_val: 0.7185
Epoch 160, training loss: 0.4606909453868866
acc_val: 0.7185
Epoch 170, training loss: 0.4224100112915039
acc_val: 0.7222
Epoch 180, training loss: 0.4253753125667572
acc_val: 0.7185
Epoch 190, training loss: 0.3935708701610565
acc_val: 0.7296
=== picking the best model according to the performance on validation ===
Training encoder Finished!
Total time elapsed: 9.7957s
Encoder CA on clean test nodes: 0.7889
[5 1 1 ... 6 5 5]
Epoch 0, loss_inner: 1.94553, loss_target: 0.00000, homo loss: 0.50889 
acc_train_clean: 0.2144, ASR_train_attach: 0.0000, ASR_train_outter: 0.6473
Epoch 10, loss_inner: 1.70326, loss_target: 0.00000, homo loss: 0.19636 
acc_train_clean: 0.3105, ASR_train_attach: 1.0000, ASR_train_outter: 0.9962
Epoch 20, loss_inner: 1.59099, loss_target: 0.00000, homo loss: 0.12461 
acc_train_clean: 0.3105, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 30, loss_inner: 1.46034, loss_target: 0.00000, homo loss: 0.13234 
acc_train_clean: 0.3420, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 40, loss_inner: 1.31024, loss_target: 0.00000, homo loss: 0.17332 
acc_train_clean: 0.5564, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 50, loss_inner: 1.13591, loss_target: 0.00000, homo loss: 0.13974 
acc_train_clean: 0.6691, ASR_train_attach: 1.0000, ASR_train_outter: 0.9962
Epoch 60, loss_inner: 0.96803, loss_target: 0.00000, homo loss: 0.13032 
acc_train_clean: 0.7874, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 70, loss_inner: 0.82462, loss_target: 0.00000, homo loss: 0.06632 
acc_train_clean: 0.8189, ASR_train_attach: 1.0000, ASR_train_outter: 0.9944
Epoch 80, loss_inner: 0.71232, loss_target: 0.00000, homo loss: 0.06891 
acc_train_clean: 0.8540, ASR_train_attach: 1.0000, ASR_train_outter: 0.9831
Epoch 90, loss_inner: 0.62859, loss_target: 0.00000, homo loss: 0.13381 
acc_train_clean: 0.8799, ASR_train_attach: 1.0000, ASR_train_outter: 0.9962
Epoch 100, loss_inner: 0.56731, loss_target: 0.00000, homo loss: 0.13262 
acc_train_clean: 0.8854, ASR_train_attach: 1.0000, ASR_train_outter: 0.9944
Epoch 110, loss_inner: 0.51370, loss_target: 0.00000, homo loss: 0.06732 
acc_train_clean: 0.8946, ASR_train_attach: 1.0000, ASR_train_outter: 0.9887
Epoch 120, loss_inner: 0.47612, loss_target: 0.00000, homo loss: 0.08789 
acc_train_clean: 0.9076, ASR_train_attach: 1.0000, ASR_train_outter: 0.9831
Epoch 130, loss_inner: 0.44950, loss_target: 0.00000, homo loss: 0.08787 
acc_train_clean: 0.9242, ASR_train_attach: 0.9524, ASR_train_outter: 0.9550
Epoch 140, loss_inner: 0.42516, loss_target: 0.00000, homo loss: 0.23584 
acc_train_clean: 0.9261, ASR_train_attach: 1.0000, ASR_train_outter: 0.9869
Epoch 150, loss_inner: 0.40520, loss_target: 0.00000, homo loss: 0.13504 
acc_train_clean: 0.9261, ASR_train_attach: 0.9524, ASR_train_outter: 0.9568
Epoch 160, loss_inner: 0.38584, loss_target: 0.00000, homo loss: 0.13404 
acc_train_clean: 0.9242, ASR_train_attach: 1.0000, ASR_train_outter: 0.9681
Epoch 170, loss_inner: 0.37127, loss_target: 0.00000, homo loss: 0.26584 
acc_train_clean: 0.9279, ASR_train_attach: 1.0000, ASR_train_outter: 0.9775
Epoch 180, loss_inner: 0.36645, loss_target: 0.00000, homo loss: 0.25042 
acc_train_clean: 0.9261, ASR_train_attach: 1.0000, ASR_train_outter: 0.9531
Epoch 190, loss_inner: 0.36761, loss_target: 0.00000, homo loss: 0.10711 
acc_train_clean: 0.9298, ASR_train_attach: 1.0000, ASR_train_outter: 0.9456
precent of left attach nodes: 1.000
target class rate on Vs: 0.9524
accuracy on clean test nodes: 0.8407
ASR: 0.8672
CA: 0.8222
