nohup: ignoring input
Namespace(attack_method='GTA', cuda=True, dataset='Cora', debug=True, defense_mode='prune', device_id=1, dis_weight=1, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.5, homo_loss_weight=1.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.1, seed=10, selection_method='cluster', target_class=0, target_loss_weight=1, test_model='GCN', thrd=0.5, trigger_prob=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Length of training set: 541
Training benign model Finished!
Total time elapsed: 2.2868s
Benign CA: 0.8444
Length of training set: 541
=== training gcn model ===
Epoch 0, training loss: 1.9322519302368164
acc_val: 0.2926
Epoch 10, training loss: 1.8021061420440674
acc_val: 0.3037
Epoch 20, training loss: 1.7138646841049194
acc_val: 0.3037
Epoch 30, training loss: 1.4916402101516724
acc_val: 0.3704
Epoch 40, training loss: 1.2497543096542358
acc_val: 0.4222
Epoch 50, training loss: 1.0791826248168945
acc_val: 0.4852
Epoch 60, training loss: 0.9507980942726135
acc_val: 0.5519
Epoch 70, training loss: 0.8186353445053101
acc_val: 0.5889
Epoch 80, training loss: 0.7561425566673279
acc_val: 0.6037
Epoch 90, training loss: 0.7051460146903992
acc_val: 0.6815
Epoch 100, training loss: 0.6418095231056213
acc_val: 0.7037
Epoch 110, training loss: 0.5879092812538147
acc_val: 0.6963
Epoch 120, training loss: 0.5704200267791748
acc_val: 0.7074
Epoch 130, training loss: 0.5387672185897827
acc_val: 0.7222
Epoch 140, training loss: 0.5038884878158569
acc_val: 0.7111
Epoch 150, training loss: 0.495248407125473
acc_val: 0.7148
Epoch 160, training loss: 0.4624980092048645
acc_val: 0.7111
Epoch 170, training loss: 0.4240918457508087
acc_val: 0.7222
Epoch 180, training loss: 0.42645812034606934
acc_val: 0.7185
Epoch 190, training loss: 0.3937922418117523
acc_val: 0.7296
=== picking the best model according to the performance on validation ===
Training encoder Finished!
Total time elapsed: 1.5674s
Encoder CA on clean test nodes: 0.7926
[4 1 1 ... 6 4 4]
Epoch 0, loss_inner: 1.94555, loss_target: 1.90138, homo loss: 0.50854 
acc_train_clean: 0.2107, ASR_train_attach: 0.0000, ASR_train_outter: 0.7017
Epoch 10, loss_inner: 1.69418, loss_target: 0.96753, homo loss: 0.46874 
acc_train_clean: 0.3142, ASR_train_attach: 0.9524, ASR_train_outter: 0.9962
Epoch 20, loss_inner: 1.55890, loss_target: 0.89938, homo loss: 0.30565 
acc_train_clean: 0.3142, ASR_train_attach: 0.9524, ASR_train_outter: 1.0000
Epoch 30, loss_inner: 1.42284, loss_target: 0.86437, homo loss: 0.29861 
acc_train_clean: 0.4547, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 40, loss_inner: 1.27795, loss_target: 0.79880, homo loss: 0.27616 
acc_train_clean: 0.5915, ASR_train_attach: 0.7143, ASR_train_outter: 0.9325
Epoch 50, loss_inner: 1.09039, loss_target: 0.66812, homo loss: 0.29555 
acc_train_clean: 0.7006, ASR_train_attach: 1.0000, ASR_train_outter: 0.9944
Epoch 60, loss_inner: 0.94170, loss_target: 0.78456, homo loss: 0.27834 
acc_train_clean: 0.7930, ASR_train_attach: 1.0000, ASR_train_outter: 0.9887
Epoch 70, loss_inner: 0.79662, loss_target: 0.54724, homo loss: 0.28788 
acc_train_clean: 0.8133, ASR_train_attach: 1.0000, ASR_train_outter: 0.9944
Epoch 80, loss_inner: 0.69113, loss_target: 0.52237, homo loss: 0.26552 
acc_train_clean: 0.8558, ASR_train_attach: 0.9524, ASR_train_outter: 0.9606
Epoch 90, loss_inner: 0.61398, loss_target: 0.43077, homo loss: 0.25534 
acc_train_clean: 0.8780, ASR_train_attach: 0.8571, ASR_train_outter: 0.9493
Epoch 100, loss_inner: 0.55304, loss_target: 0.45314, homo loss: 0.25161 
acc_train_clean: 0.8909, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 110, loss_inner: 0.50366, loss_target: 0.35444, homo loss: 0.26161 
acc_train_clean: 0.9020, ASR_train_attach: 1.0000, ASR_train_outter: 0.9756
Epoch 120, loss_inner: 0.46687, loss_target: 0.32538, homo loss: 0.24381 
acc_train_clean: 0.9242, ASR_train_attach: 0.9524, ASR_train_outter: 0.9756
Epoch 130, loss_inner: 0.44887, loss_target: 0.47858, homo loss: 0.24438 
acc_train_clean: 0.9150, ASR_train_attach: 1.0000, ASR_train_outter: 1.0000
Epoch 140, loss_inner: 0.42621, loss_target: 0.32196, homo loss: 0.24402 
acc_train_clean: 0.9224, ASR_train_attach: 1.0000, ASR_train_outter: 0.9831
Epoch 150, loss_inner: 0.39597, loss_target: 0.30773, homo loss: 0.23831 
acc_train_clean: 0.9427, ASR_train_attach: 0.8571, ASR_train_outter: 0.9681
Epoch 160, loss_inner: 0.37462, loss_target: 0.34308, homo loss: 0.23700 
acc_train_clean: 0.9335, ASR_train_attach: 1.0000, ASR_train_outter: 0.9981
Epoch 170, loss_inner: 0.36478, loss_target: 0.28090, homo loss: 0.23329 
acc_train_clean: 0.9427, ASR_train_attach: 0.9048, ASR_train_outter: 0.9925
Epoch 180, loss_inner: 0.36394, loss_target: 0.33635, homo loss: 0.22364 
acc_train_clean: 0.9427, ASR_train_attach: 0.9048, ASR_train_outter: 0.9587
Epoch 190, loss_inner: 0.34405, loss_target: 0.25802, homo loss: 0.21921 
acc_train_clean: 0.9445, ASR_train_attach: 0.9048, ASR_train_outter: 0.9719
precent of left attach nodes: 1.000
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.8185
ASR: 0.9299
CA: 0.7370
