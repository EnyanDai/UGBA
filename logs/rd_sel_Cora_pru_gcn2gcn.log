nohup: ignoring input
Namespace(attack_method='Rand_Gene', cuda=True, dataset='Cora', debug=True, defense_mode='prune', device_id=1, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.5, homo_loss_weight=1.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.3, seed=10, selection_method='cluster', target_class=0, test_model='GCN', thrd=0.5, trigger_prob=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Length of training set: 541
Training benign model Finished!
Total time elapsed: 2.6972s
Benign CA: 0.8444
Length of training set: 541
=== training gcn model ===
Epoch 0, training loss: 1.9322519302368164
acc_val: 0.2926
Epoch 10, training loss: 1.8021061420440674
acc_val: 0.3037
Epoch 20, training loss: 1.7138646841049194
acc_val: 0.3037
Epoch 30, training loss: 1.4916402101516724
acc_val: 0.3704
Epoch 40, training loss: 1.2497543096542358
acc_val: 0.4222
Epoch 50, training loss: 1.0791826248168945
acc_val: 0.4852
Epoch 60, training loss: 0.9507980942726135
acc_val: 0.5519
Epoch 70, training loss: 0.8186353445053101
acc_val: 0.5889
Epoch 80, training loss: 0.7561426758766174
acc_val: 0.6037
Epoch 90, training loss: 0.7051459550857544
acc_val: 0.6815
Epoch 100, training loss: 0.6418095827102661
acc_val: 0.7037
Epoch 110, training loss: 0.5879091620445251
acc_val: 0.6963
Epoch 120, training loss: 0.5704082250595093
acc_val: 0.7074
Epoch 130, training loss: 0.538766086101532
acc_val: 0.7222
Epoch 140, training loss: 0.5040132999420166
acc_val: 0.7074
Epoch 150, training loss: 0.4945518374443054
acc_val: 0.7148
Epoch 160, training loss: 0.46507272124290466
acc_val: 0.7111
Epoch 170, training loss: 0.4249529242515564
acc_val: 0.7185
Epoch 180, training loss: 0.42690134048461914
acc_val: 0.7111
Epoch 190, training loss: 0.39474916458129883
acc_val: 0.7333
=== picking the best model according to the performance on validation ===
Training encoder Finished!
Total time elapsed: 1.7636s
Encoder CA on clean test nodes: 0.7926
[0 3 3 ... 5 0 0]
Epoch 0, loss_inner: 1.94566, loss_target: 0.00000, homo loss: 0.48774 
acc_train_clean: 0.2144, ASR_train_attach: 0.0000, ASR_train_outter: 0.1576
Epoch 10, loss_inner: 1.67730, loss_target: 0.00000, homo loss: 0.48822 
acc_train_clean: 0.3198, ASR_train_attach: 0.9048, ASR_train_outter: 0.2045
Epoch 20, loss_inner: 1.47869, loss_target: 0.00000, homo loss: 0.48833 
acc_train_clean: 0.3494, ASR_train_attach: 0.9524, ASR_train_outter: 0.6548
Epoch 30, loss_inner: 1.27477, loss_target: 0.00000, homo loss: 0.48706 
acc_train_clean: 0.6192, ASR_train_attach: 1.0000, ASR_train_outter: 0.4053
Epoch 40, loss_inner: 1.06848, loss_target: 0.00000, homo loss: 0.48750 
acc_train_clean: 0.7597, ASR_train_attach: 1.0000, ASR_train_outter: 0.4184
Epoch 50, loss_inner: 0.88543, loss_target: 0.00000, homo loss: 0.48702 
acc_train_clean: 0.8096, ASR_train_attach: 1.0000, ASR_train_outter: 0.4334
Epoch 60, loss_inner: 0.74402, loss_target: 0.00000, homo loss: 0.48767 
acc_train_clean: 0.8373, ASR_train_attach: 1.0000, ASR_train_outter: 0.4034
Epoch 70, loss_inner: 0.63585, loss_target: 0.00000, homo loss: 0.48715 
acc_train_clean: 0.8725, ASR_train_attach: 1.0000, ASR_train_outter: 0.4447
Epoch 80, loss_inner: 0.55667, loss_target: 0.00000, homo loss: 0.48685 
acc_train_clean: 0.9002, ASR_train_attach: 0.9524, ASR_train_outter: 0.3902
Epoch 90, loss_inner: 0.49789, loss_target: 0.00000, homo loss: 0.48809 
acc_train_clean: 0.9131, ASR_train_attach: 0.9524, ASR_train_outter: 0.3715
Epoch 100, loss_inner: 0.45045, loss_target: 0.00000, homo loss: 0.48774 
acc_train_clean: 0.9261, ASR_train_attach: 1.0000, ASR_train_outter: 0.4184
Epoch 110, loss_inner: 0.41574, loss_target: 0.00000, homo loss: 0.48880 
acc_train_clean: 0.9298, ASR_train_attach: 1.0000, ASR_train_outter: 0.3771
Epoch 120, loss_inner: 0.38777, loss_target: 0.00000, homo loss: 0.48726 
acc_train_clean: 0.9335, ASR_train_attach: 1.0000, ASR_train_outter: 0.3959
Epoch 130, loss_inner: 0.36545, loss_target: 0.00000, homo loss: 0.48804 
acc_train_clean: 0.9409, ASR_train_attach: 1.0000, ASR_train_outter: 0.3884
Epoch 140, loss_inner: 0.34723, loss_target: 0.00000, homo loss: 0.48702 
acc_train_clean: 0.9427, ASR_train_attach: 1.0000, ASR_train_outter: 0.3790
Epoch 150, loss_inner: 0.33214, loss_target: 0.00000, homo loss: 0.48711 
acc_train_clean: 0.9519, ASR_train_attach: 1.0000, ASR_train_outter: 0.3621
Epoch 160, loss_inner: 0.32147, loss_target: 0.00000, homo loss: 0.48626 
acc_train_clean: 0.9538, ASR_train_attach: 0.9524, ASR_train_outter: 0.4015
Epoch 170, loss_inner: 0.30844, loss_target: 0.00000, homo loss: 0.48726 
acc_train_clean: 0.9556, ASR_train_attach: 1.0000, ASR_train_outter: 0.4034
Epoch 180, loss_inner: 0.29893, loss_target: 0.00000, homo loss: 0.48774 
acc_train_clean: 0.9575, ASR_train_attach: 1.0000, ASR_train_outter: 0.4090
Epoch 190, loss_inner: 0.29145, loss_target: 0.00000, homo loss: 0.48801 
acc_train_clean: 0.9556, ASR_train_attach: 0.9524, ASR_train_outter: 0.3640
precent of left attach nodes: 1.000
target class rate on Vs: 0.9048
accuracy on clean test nodes: 0.7852
ASR: 0.2030
CA: 0.7370
