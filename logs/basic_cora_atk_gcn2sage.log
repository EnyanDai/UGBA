nohup: ignoring input
Namespace(clean_test_nodes_num=200, cuda=True, dataset='cora', debug=True, defense_mode='none', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=0.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.1, seed=10, target_class=0, target_test_nodes_num=200, test_model='GraphSage', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.8360
Benign CA on clean test nodes: 0.7800
2708
200
Epoch 0, training loss: 1.9394763708114624
acc_train_clean: 0.1768, acc_train_attach: 0.0000
Epoch 10, training loss: 0.5679745078086853
acc_train_clean: 0.9071, acc_train_attach: 1.0000
Epoch 20, training loss: 0.20934630930423737
acc_train_clean: 0.9411, acc_train_attach: 1.0000
Epoch 30, training loss: 0.12698887288570404
acc_train_clean: 0.9643, acc_train_attach: 1.0000
Epoch 40, training loss: 0.09730815887451172
acc_train_clean: 0.9750, acc_train_attach: 1.0000
Epoch 50, training loss: 0.06966764479875565
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 60, training loss: 0.09380032122135162
acc_train_clean: 0.9857, acc_train_attach: 0.9412
Epoch 70, training loss: 0.07424837350845337
acc_train_clean: 0.9821, acc_train_attach: 1.0000
Epoch 80, training loss: 0.07422423362731934
acc_train_clean: 0.9857, acc_train_attach: 0.8824
Epoch 90, training loss: 0.058609552681446075
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 100, training loss: 0.06764553487300873
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 110, training loss: 0.05955095589160919
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 120, training loss: 0.054839808493852615
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 130, training loss: 0.05726291611790657
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 140, training loss: 0.05871827155351639
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 150, training loss: 0.059812337160110474
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 160, training loss: 0.05576128885149956
acc_train_clean: 0.9911, acc_train_attach: 1.0000
Epoch 170, training loss: 0.04570222645998001
acc_train_clean: 0.9929, acc_train_attach: 1.0000
Epoch 180, training loss: 0.05446925386786461
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 190, training loss: 0.04583087936043739
acc_train_clean: 0.9893, acc_train_attach: 1.0000
577
577
4306 4306
{2242, 1506, 2436, 1157, 1734, 2276, 1029, 2089, 1894, 2502, 430, 1743, 1969, 213, 1591, 183, 2204}
=== training gcn model ===
Epoch 0, training loss: 1.9449214935302734
acc_val: 0.1850
Epoch 10, training loss: 0.3162356913089752
acc_val: 0.7675
Epoch 20, training loss: 0.09464582055807114
acc_val: 0.7725
Epoch 30, training loss: 0.04237927496433258
acc_val: 0.7800
Epoch 40, training loss: 0.028572548180818558
acc_val: 0.7700
Epoch 50, training loss: 0.02340581640601158
acc_val: 0.7800
Epoch 60, training loss: 0.02759643644094467
acc_val: 0.7925
Epoch 70, training loss: 0.03138928860425949
acc_val: 0.7825
Epoch 80, training loss: 0.029115067794919014
acc_val: 0.8050
Epoch 90, training loss: 0.027058808133006096
acc_val: 0.7900
Epoch 100, training loss: 0.02598024159669876
acc_val: 0.7950
Epoch 110, training loss: 0.024624601006507874
acc_val: 0.7875
Epoch 120, training loss: 0.020729050040245056
acc_val: 0.7875
Epoch 130, training loss: 0.02682706154882908
acc_val: 0.7850
Epoch 140, training loss: 0.02096402645111084
acc_val: 0.7775
Epoch 150, training loss: 0.024579573422670364
acc_val: 0.7775
Epoch 160, training loss: 0.030466511845588684
acc_val: 0.7825
Epoch 170, training loss: 0.03394279628992081
acc_val: 0.7750
Epoch 180, training loss: 0.020916514098644257
acc_val: 0.7925
Epoch 190, training loss: 0.027156632393598557
acc_val: 0.7850
=== picking the best model according to the performance on validation ===
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.8000
ASR: 0.9800
CA: 0.7950
