nohup: ignoring input
/home/project-graph-backdoor/Backdoor/models/GAT.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.labels = torch.tensor(labels, dtype=torch.long)
Namespace(clean_test_nodes_num=200, cuda=True, dataset='citeseer', debug=True, defense_mode='none', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=0.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.1, seed=10, target_class=0, target_test_nodes_num=200, test_model='GAT', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.7100
Benign CA on clean test nodes: 0.6450
3327
200
Epoch 0, training loss: 1.8009929656982422
acc_train_clean: 0.1479, acc_train_attach: 0.1304
Epoch 10, training loss: 0.2316441535949707
acc_train_clean: 0.9437, acc_train_attach: 1.0000
Epoch 20, training loss: 0.07828577607870102
acc_train_clean: 0.9771, acc_train_attach: 1.0000
Epoch 30, training loss: 0.0522325225174427
acc_train_clean: 0.9854, acc_train_attach: 1.0000
Epoch 40, training loss: 0.049033988267183304
acc_train_clean: 0.9833, acc_train_attach: 1.0000
Epoch 50, training loss: 0.05811046436429024
acc_train_clean: 0.9833, acc_train_attach: 1.0000
Epoch 60, training loss: 0.04916088283061981
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 70, training loss: 0.06508301198482513
acc_train_clean: 0.9896, acc_train_attach: 0.9565
Epoch 80, training loss: 0.054915811866521835
acc_train_clean: 0.9833, acc_train_attach: 0.9565
Epoch 90, training loss: 0.05036639794707298
acc_train_clean: 0.9917, acc_train_attach: 1.0000
Epoch 100, training loss: 0.044989679008722305
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 110, training loss: 0.043855421245098114
acc_train_clean: 0.9854, acc_train_attach: 1.0000
Epoch 120, training loss: 0.043263569474220276
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 130, training loss: 0.032564982771873474
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 140, training loss: 0.03702978044748306
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 150, training loss: 0.033731766045093536
acc_train_clean: 0.9917, acc_train_attach: 1.0000
Epoch 160, training loss: 0.04221523553133011
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 170, training loss: 0.03253118693828583
acc_train_clean: 0.9938, acc_train_attach: 1.0000
Epoch 180, training loss: 0.03435198590159416
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 190, training loss: 0.04441659525036812
acc_train_clean: 0.9917, acc_train_attach: 1.0000
503
503
4454 4454
{1152, 2062, 1945, 3239, 1461, 57, 2371, 195, 2118, 1478, 1481, 2506, 1741, 1366, 3031, 1115, 3038, 3294, 350, 2537, 1778, 499, 1785}
=== training gcn model ===
Epoch 0, training loss: 1.8508764505386353
acc_val: 0.1875
Epoch 10, training loss: 0.7612669467926025
acc_val: 0.6625
Epoch 20, training loss: 0.7078991532325745
acc_val: 0.6750
Epoch 30, training loss: 0.7012568116188049
acc_val: 0.6800
Epoch 40, training loss: 0.6466404795646667
acc_val: 0.6650
Epoch 50, training loss: 0.5881588459014893
acc_val: 0.6875
Epoch 60, training loss: 0.5514342784881592
acc_val: 0.6850
Epoch 70, training loss: 0.611575722694397
acc_val: 0.6850
Epoch 80, training loss: 0.5985509157180786
acc_val: 0.6850
Epoch 90, training loss: 0.5909774899482727
acc_val: 0.6725
Epoch 100, training loss: 0.6052311062812805
acc_val: 0.6850
Epoch 110, training loss: 0.6256133913993835
acc_val: 0.6625
Epoch 120, training loss: 0.582221269607544
acc_val: 0.6750
Epoch 130, training loss: 0.611635148525238
acc_val: 0.7050
Epoch 140, training loss: 0.5962460041046143
acc_val: 0.7000
Epoch 150, training loss: 0.6078534722328186
acc_val: 0.6625
Epoch 160, training loss: 0.5534341931343079
acc_val: 0.6775
Epoch 170, training loss: 0.4173900783061981
acc_val: 0.6850
Epoch 180, training loss: 0.6289055347442627
acc_val: 0.6825
Epoch 190, training loss: 0.5681719183921814
acc_val: 0.6975
=== picking the best model according to the performance on validation ===
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.6950
ASR: 1.0000
CA: 0.6950
