nohup: ignoring input
Namespace(clean_test_nodes_num=200, cuda=True, dataset='pubmed', debug=True, defense_mode='none', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=1.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.1, seed=10, target_class=0, target_test_nodes_num=200, test_model='GCN', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.8110
Benign CA on clean test nodes: 0.7400
19717
200
tensor(1.0985, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(224.4008, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 0, training loss: 1.098490834236145
acc_train_clean: 0.2083, acc_train_attach: 0.3155
tensor(1.0689, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(224.4008, device='cuda:5', grad_fn=<MulBackward0>)
tensor(1.0376, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(224.4008, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6292, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(135.0875, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6320, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6368, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6205, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6270, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6094, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6098, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6021, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 10, training loss: 0.6021488904953003
acc_train_clean: 0.3417, acc_train_attach: 1.0000
tensor(0.5978, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5941, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5909, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5850, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5755, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5628, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5649, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5495, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4155, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5461, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.0076, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 20, training loss: 0.5461322665214539
acc_train_clean: 0.4708, acc_train_attach: 1.0000
tensor(0.5385, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(133.8110, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5369, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(132.8424, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5305, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(132.6205, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5241, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(133.4531, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5175, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(133.6751, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5065, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(133.7466, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4936, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(132.4846, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4897, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.2220, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4872, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(130.7412, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4759, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(130.7652, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 30, training loss: 0.475903183221817
acc_train_clean: 0.7583, acc_train_attach: 1.0000
tensor(0.4726, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.4144, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4773, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.8127, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4604, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.7422, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4575, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.6431, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4495, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(130.4086, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4511, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(128.7410, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4446, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(128.3509, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4343, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.4064, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4151, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.2086, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4085, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(126.0408, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 40, training loss: 0.4084673523902893
acc_train_clean: 0.8333, acc_train_attach: 1.0000
tensor(0.3963, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(125.9906, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3954, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(125.6415, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4121, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(126.5598, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4060, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.6414, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3903, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.2673, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3907, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.4493, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3954, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(125.3996, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3815, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(124.3683, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3547, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(123.6217, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3666, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.5327, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 50, training loss: 0.3665613830089569
acc_train_clean: 0.8375, acc_train_attach: 1.0000
tensor(0.3600, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(121.8507, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3551, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.4342, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3686, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.6879, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3682, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(123.2874, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3374, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(124.8525, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3218, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(123.6914, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3175, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.4328, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3162, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.0106, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3140, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(120.6996, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3075, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(120.9894, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 60, training loss: 0.3074893355369568
acc_train_clean: 0.8583, acc_train_attach: 0.9947
tensor(0.2941, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(120.9892, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3096, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(120.4257, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3183, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.5174, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3087, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.4052, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3168, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(117.5866, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3052, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(117.9509, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2901, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.2550, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2874, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.2966, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2814, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(117.7075, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2824, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.4017, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 70, training loss: 0.28237074613571167
acc_train_clean: 0.8500, acc_train_attach: 1.0000
tensor(0.2834, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(117.6927, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2787, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(116.7205, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2593, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(116.7876, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2597, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(116.5502, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2607, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.9126, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2710, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.4094, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2782, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.5491, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2512, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.2541, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2748, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.6201, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2510, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.6899, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 80, training loss: 0.25101253390312195
acc_train_clean: 0.8708, acc_train_attach: 1.0000
tensor(0.2551, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.6782, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2440, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.4544, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2590, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.4119, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2378, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.6273, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2379, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.0707, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2239, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.4620, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2441, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.9126, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2268, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.6817, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2253, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.2912, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2291, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.2359, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 90, training loss: 0.22907328605651855
acc_train_clean: 0.9042, acc_train_attach: 0.9947
tensor(0.2246, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.1004, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2378, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.2267, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2169, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.3356, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2086, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.8712, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2474, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.3643, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2128, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.7862, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2111, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.8738, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2234, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.6106, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2145, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.5518, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2228, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.0466, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 100, training loss: 0.22279983758926392
acc_train_clean: 0.9125, acc_train_attach: 1.0000
tensor(0.2256, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(111.9552, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2238, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.9712, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2120, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.9411, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2157, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(111.1191, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2232, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(111.3677, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2109, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.5965, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2107, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.8267, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2057, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.9531, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2044, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(111.1209, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2015, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.6468, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 110, training loss: 0.2015250027179718
acc_train_clean: 0.9208, acc_train_attach: 1.0000
tensor(0.1969, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.6435, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1983, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.0349, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2074, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.7010, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1934, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.4741, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2079, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.4979, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2048, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.6423, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1963, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.7723, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1943, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.6787, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1965, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.9690, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1993, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.4406, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 120, training loss: 0.19925707578659058
acc_train_clean: 0.9333, acc_train_attach: 1.0000
tensor(0.2020, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.8465, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1835, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.3922, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1920, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.5384, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1793, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.8778, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1858, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.9111, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1895, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.3462, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1771, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.8853, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1854, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.0221, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1850, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.8612, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1850, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.6049, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 130, training loss: 0.1849881261587143
acc_train_clean: 0.9333, acc_train_attach: 1.0000
tensor(0.2050, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.4797, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1865, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.4771, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1959, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.8226, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1761, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.9804, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1892, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.4273, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1880, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.1431, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1807, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.4834, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1830, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.1486, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1758, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.0954, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1663, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.8746, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 140, training loss: 0.16631565988063812
acc_train_clean: 0.9667, acc_train_attach: 1.0000
tensor(0.1705, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.5485, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1666, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4467, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1743, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.2823, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1886, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.3146, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1725, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.1116, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1751, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.3452, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1689, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.9308, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1726, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4398, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1656, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.6823, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1623, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.7632, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 150, training loss: 0.16226555407047272
acc_train_clean: 0.9500, acc_train_attach: 1.0000
tensor(0.1676, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.0850, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1626, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.1298, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1600, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.7434, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1686, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.8849, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1621, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4842, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1625, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.9862, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1654, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.5270, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1703, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4584, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1617, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2914, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.3199, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 160, training loss: 0.16273613274097443
acc_train_clean: 0.9458, acc_train_attach: 1.0000
tensor(0.1633, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.0315, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1601, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2307, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1574, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4084, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1543, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.6212, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4025, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1566, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2886, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1513, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.8182, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1510, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.9992, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1664, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.4948, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1465, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.8928, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 170, training loss: 0.14645183086395264
acc_train_clean: 0.9625, acc_train_attach: 1.0000
tensor(0.1463, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.2039, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1553, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.6731, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1702, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.6349, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1569, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.2761, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1504, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2175, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1551, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.6871, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1494, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.5746, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1615, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.5494, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1664, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.9698, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1487, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.0305, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 180, training loss: 0.148696169257164
acc_train_clean: 0.9583, acc_train_attach: 1.0000
tensor(0.1383, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.6942, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1556, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.8016, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1651, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.7742, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1479, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3978, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1422, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3359, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1480, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.1710, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1480, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.1760, device='cuda:5', grad_fn=<MulBackward0>)
/home/project-graph-backdoor/Backdoor/help_funcs.py:80: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
tensor(0.1519, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.9268, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1468, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3006, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1465, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.2924, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 190, training loss: 0.14652091264724731
acc_train_clean: 0.9542, acc_train_attach: 0.9947
tensor(0.1467, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.6176, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1535, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.7318, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1538, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3823, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1411, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.0483, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1355, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.4618, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1442, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.2088, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1437, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.4772, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1497, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.7407, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1553, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.4450, device='cuda:5', grad_fn=<MulBackward0>)
427
427
81052 81052
{11777, 10246, 7175, 17928, 15370, 13326, 12816, 17914, 2067, 15892, 1530, 3606, 10776, 15385, 17438, 1566, 12833, 16419, 18983, 13352, 4650, 45, 15919, 4145, 8753, 8755, 6201, 9785, 12864, 64, 10307, 4676, 7754, 3147, 16460, 19533, 9294, 1101, 4176, 7245, 19539, 13395, 4179, 4692, 10839, 15448, 3680, 3681, 3170, 7274, 9324, 11373, 14454, 19584, 128, 12419, 10884, 4742, 2183, 11400, 6283, 1680, 18066, 6805, 6294, 5277, 11935, 15009, 10408, 16552, 19122, 8371, 14005, 14011, 19132, 8905, 9930, 13517, 7374, 12494, 18642, 5332, 7384, 8926, 6369, 226, 9445, 235, 4849, 753, 9460, 7414, 10492, 11007, 18176, 16130, 3845, 14086, 16645, 9993, 1296, 7959, 15640, 15132, 18722, 15145, 8494, 7473, 2354, 5427, 6964, 13621, 6455, 1855, 4933, 8522, 15178, 14156, 11084, 18250, 16717, 9043, 12627, 16728, 9563, 12637, 8547, 5987, 16741, 2917, 4970, 18799, 14193, 17778, 3955, 17266, 374, 14713, 6012, 2941, 16256, 12164, 6532, 3974, 18311, 8588, 19341, 19350, 17303, 3481, 7580, 17824, 14753, 8609, 17316, 6565, 7592, 6570, 17835, 18348, 2478, 6575, 9141, 14263, 14780, 12221, 15294, 8646, 17865, 6606, 3541, 2520, 9181, 5092, 6628, 18918, 11751, 15848, 15845, 4076, 4589, 2543, 5103, 10226, 2554, 6651, 3068}
=== training gcn model ===
Epoch 0, training loss: 1.0933235883712769
acc_val: 0.2275
Epoch 10, training loss: 0.6469035744667053
acc_val: 0.2275
Epoch 20, training loss: 0.6035162210464478
acc_val: 0.2300
Epoch 30, training loss: 0.579483687877655
acc_val: 0.6975
Epoch 40, training loss: 0.5367935299873352
acc_val: 0.7550
Epoch 50, training loss: 0.495853990316391
acc_val: 0.7325
Epoch 60, training loss: 0.4514749050140381
acc_val: 0.7775
Epoch 70, training loss: 0.3872646987438202
acc_val: 0.7725
Epoch 80, training loss: 0.3642127811908722
acc_val: 0.7825
Epoch 90, training loss: 0.3279518187046051
acc_val: 0.7800
Epoch 100, training loss: 0.31709232926368713
acc_val: 0.7875
Epoch 110, training loss: 0.27826905250549316
acc_val: 0.7925
Epoch 120, training loss: 0.27512359619140625
acc_val: 0.8000
Epoch 130, training loss: 0.25952261686325073
acc_val: 0.7900
Epoch 140, training loss: 0.24234598875045776
acc_val: 0.8150
Epoch 150, training loss: 0.23252113163471222
acc_val: 0.8050
Epoch 160, training loss: 0.23590441048145294
acc_val: 0.7875
Epoch 170, training loss: 0.23767825961112976
acc_val: 0.8000
Epoch 180, training loss: 0.22121165692806244
acc_val: 0.8075
Epoch 190, training loss: 0.21137557923793793
acc_val: 0.8100
=== picking the best model according to the performance on validation ===
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.7750
ASR: 1.0000
CA: 0.7500

