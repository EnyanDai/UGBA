nohup: ignoring input
Namespace(clean_test_nodes_num=200, cuda=True, dataset='cora', debug=True, defense_mode='isolate', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=1.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.1, seed=10, target_class=0, target_test_nodes_num=200, test_model='GCN', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.8360
Benign CA on clean test nodes: 0.7800
2708
200
tensor(1.9395, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(20.4000, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 0, training loss: 1.9394763708114624
acc_train_clean: 0.1768, acc_train_attach: 0.0000
tensor(1.7910, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(8.4708, device='cuda:5', grad_fn=<MulBackward0>)
tensor(1.6239, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(12.5005, device='cuda:5', grad_fn=<MulBackward0>)
tensor(1.4373, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(12.0582, device='cuda:5', grad_fn=<MulBackward0>)
tensor(1.2905, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(10.7606, device='cuda:5', grad_fn=<MulBackward0>)
tensor(1.1322, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(9.8844, device='cuda:5', grad_fn=<MulBackward0>)
tensor(1.0009, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(8.1433, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.8901, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(6.6891, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.7913, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(5.6920, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.7016, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(4.4478, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5769, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(3.7621, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 10, training loss: 0.5769366025924683
acc_train_clean: 0.9089, acc_train_attach: 0.9412
tensor(0.5221, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(3.2531, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4807, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(2.9389, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4095, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(2.6986, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3534, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(2.1517, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3269, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.9518, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2999, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.9121, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2844, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.5390, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2460, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.6180, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2453, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.4569, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2168, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.3461, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 20, training loss: 0.2168077528476715
acc_train_clean: 0.9411, acc_train_attach: 1.0000
tensor(0.2165, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.4080, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1971, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.0009, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1871, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.7671, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1906, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.9759, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1520, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.9168, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1508, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.1134, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.7089, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1295, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.7336, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1398, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.9197, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1352, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.5698, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 30, training loss: 0.1352093666791916
acc_train_clean: 0.9589, acc_train_attach: 0.9412
tensor(0.1215, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(1.0396, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1300, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.6746, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1186, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.5072, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1010, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.4422, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1154, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.8181, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1042, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.7034, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1175, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3835, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1005, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.4051, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0963, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.4506, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1041, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.5282, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 40, training loss: 0.10413006693124771
acc_train_clean: 0.9768, acc_train_attach: 0.8824
tensor(0.1011, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.6398, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0824, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3598, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1107, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.4254, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0950, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.6078, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0938, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.4539, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0873, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3195, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0905, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3056, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0781, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3835, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0747, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.5644, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0785, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.4783, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 50, training loss: 0.07850217074155807
acc_train_clean: 0.9857, acc_train_attach: 0.9412
tensor(0.0776, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2392, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0829, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3922, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0914, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2678, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0777, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2392, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0813, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3345, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0859, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2573, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0738, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1674, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0840, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1555, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0712, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.4254, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0959, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1743, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 60, training loss: 0.09586642682552338
acc_train_clean: 0.9750, acc_train_attach: 0.9412
tensor(0.0804, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1046, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0821, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1419, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0748, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0999, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0724, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2845, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0858, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1046, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0858, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1046, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0859, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1199, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0723, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0845, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0501, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0778, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1199, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 70, training loss: 0.0778297409415245
acc_train_clean: 0.9786, acc_train_attach: 1.0000
tensor(0.0752, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1046, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0752, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1880, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0846, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0048, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0704, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0759, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2076, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0671, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0718, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0684, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1153, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0854, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0826, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1031, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0723, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
Epoch 80, training loss: 0.07234153151512146
acc_train_clean: 0.9839, acc_train_attach: 0.9412
tensor(0.0680, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1764, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0744, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2241, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0779, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0790, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0048, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0742, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0718, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0682, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1046, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0716, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0673, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0675, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0501, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0645, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3128, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0644, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
Epoch 90, training loss: 0.06441794335842133
acc_train_clean: 0.9893, acc_train_attach: 1.0000
tensor(0.0719, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1046, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0875, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2544, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0669, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0697, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3780, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0743, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0813, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2059, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0731, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1572, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0706, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0673, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0722, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2415, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 100, training loss: 0.07217560708522797
acc_train_clean: 0.9857, acc_train_attach: 1.0000
tensor(0.0607, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1581, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0700, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0680, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0743, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3066, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0655, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0966, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0639, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0048, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0620, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0642, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1499, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0716, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2761, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0612, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1606, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 110, training loss: 0.06119688227772713
acc_train_clean: 0.9839, acc_train_attach: 1.0000
tensor(0.0627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0617, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0559, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0606, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0620, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1555, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0574, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1417, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0591, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0215, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0700, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2688, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0694, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0501, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0712, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2522, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0606, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 120, training loss: 0.06062089651823044
acc_train_clean: 0.9893, acc_train_attach: 0.9412
tensor(0.0585, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0626, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0699, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1633, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0550, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0543, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0648, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1046, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0607, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0682, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1546, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0587, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2217, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0596, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0709, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 130, training loss: 0.059570081532001495
acc_train_clean: 0.9875, acc_train_attach: 1.0000
tensor(0.0564, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0587, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0521, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0629, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0501, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0602, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0565, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0671, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0614, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0978, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0604, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0553, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0598, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
Epoch 140, training loss: 0.05981365963816643
acc_train_clean: 0.9893, acc_train_attach: 1.0000
tensor(0.0577, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0623, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2425, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0570, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0048, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0561, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0608, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0568, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0510, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0634, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0048, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0629, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
Epoch 150, training loss: 0.06288407742977142
acc_train_clean: 0.9857, acc_train_attach: 1.0000
tensor(0.0557, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0581, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1555, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0573, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1279, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0665, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3056, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0667, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0551, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0575, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0547, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0241, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0584, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0591, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2000, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 160, training loss: 0.05911751464009285
acc_train_clean: 0.9893, acc_train_attach: 1.0000
tensor(0.0538, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1912, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0563, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0515, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0670, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0491, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0597, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0591, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0639, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0881, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0466, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0345, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0591, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0532, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
Epoch 170, training loss: 0.053156763315200806
acc_train_clean: 0.9911, acc_train_attach: 0.8824
tensor(0.0535, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0820, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0517, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1075, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0578, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0485, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0470, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0552, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1505, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0550, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0550, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1858, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0632, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0529, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0601, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
Epoch 180, training loss: 0.060133691877126694
acc_train_clean: 0.9893, acc_train_attach: 1.0000
tensor(0.0498, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0495, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0098, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0515, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.1046, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0503, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0954, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0576, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0505, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0521, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0529, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0517, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0168, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0504, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
Epoch 190, training loss: 0.050448134541511536
acc_train_clean: 0.9875, acc_train_attach: 0.9412
tensor(0.0486, device='cuda:5', grad_fn=<NllLossBackward0>) /home/project-graph-backdoor/Backdoor/help_funcs.py:80: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
/home/project-graph-backdoor/Backdoor/help_funcs.py:90: RuntimeWarning: divide by zero encountered in power
  d_inv_sqrt = np.power(rowsum, -0.5).flatten()
tensor(0.0048, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0505, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0118, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0512, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0611, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2008, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0556, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0564, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.0453, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0579, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.2495, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0512, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0., device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.0460, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(0.3678, device='cuda:5', grad_fn=<MulBackward0>)
tensor([[   2, 1986],
        [   9, 2614],
        [  12, 1001],
        ...,
        [2685, 2452],
        [2686, 1657],
        [2691,  206]])
577
322
4306 2880
{2242, 1506, 2276, 1029, 2502, 1969, 213, 1591}
=== training gcn model ===
Epoch 0, training loss: 1.9482721090316772
acc_val: 0.3825
Epoch 10, training loss: 0.4816691279411316
acc_val: 0.7125
Epoch 20, training loss: 0.13425292074680328
acc_val: 0.7375
Epoch 30, training loss: 0.0777752473950386
acc_val: 0.7400
Epoch 40, training loss: 0.055064763873815536
acc_val: 0.7325
Epoch 50, training loss: 0.05634743347764015
acc_val: 0.7375
Epoch 60, training loss: 0.06581224501132965
acc_val: 0.7400
Epoch 70, training loss: 0.049446940422058105
acc_val: 0.7425
Epoch 80, training loss: 0.045614197850227356
acc_val: 0.7425
Epoch 90, training loss: 0.03851492330431938
acc_val: 0.7400
Epoch 100, training loss: 0.04455840215086937
acc_val: 0.7425
Epoch 110, training loss: 0.0398210845887661
acc_val: 0.7425
Epoch 120, training loss: 0.041850920766592026
acc_val: 0.7325
Epoch 130, training loss: 0.05941055715084076
acc_val: 0.7450
Epoch 140, training loss: 0.03619493544101715
acc_val: 0.7450
Epoch 150, training loss: 0.02999943122267723
acc_val: 0.7475
Epoch 160, training loss: 0.038692452013492584
acc_val: 0.7375
Epoch 170, training loss: 0.03500241041183472
acc_val: 0.7450
Epoch 180, training loss: 0.04211335629224777
acc_val: 0.7325
Epoch 190, training loss: 0.037162959575653076
acc_val: 0.7450
=== picking the best model according to the performance on validation ===
target class rate on Vs: 0.6471
accuracy on clean test nodes: 0.7800
ASR: 0.3950
CA: 0.7300
