nohup: ignoring input
Namespace(attack_method='Rand_Samp', cuda=True, dataset='Cora', debug=True, defense_mode='none', device_id=1, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.5, homo_loss_weight=0.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.3, seed=10, selection_method='cluster', target_class=0, target_loss_weight=1, test_model='GCN', thrd=0.5, trigger_prob=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Length of training set: 541
Training benign model Finished!
Total time elapsed: 4.0359s
Benign CA: 0.8444
Length of training set: 541
=== training gcn model ===
Epoch 0, training loss: 1.9322519302368164
acc_val: 0.2926
Epoch 10, training loss: 1.8021061420440674
acc_val: 0.3037
Epoch 20, training loss: 1.7138646841049194
acc_val: 0.3037
Epoch 30, training loss: 1.4916402101516724
acc_val: 0.3704
Epoch 40, training loss: 1.2497543096542358
acc_val: 0.4222
Epoch 50, training loss: 1.079182505607605
acc_val: 0.4852
Epoch 60, training loss: 0.9507980942726135
acc_val: 0.5519
Epoch 70, training loss: 0.8186354041099548
acc_val: 0.5889
Epoch 80, training loss: 0.7561426758766174
acc_val: 0.6037
Epoch 90, training loss: 0.7051460146903992
acc_val: 0.6815
Epoch 100, training loss: 0.6418096423149109
acc_val: 0.7037
Epoch 110, training loss: 0.5879091620445251
acc_val: 0.6963
Epoch 120, training loss: 0.5704201459884644
acc_val: 0.7074
Epoch 130, training loss: 0.5387671589851379
acc_val: 0.7222
Epoch 140, training loss: 0.5038884282112122
acc_val: 0.7111
Epoch 150, training loss: 0.4952484965324402
acc_val: 0.7148
Epoch 160, training loss: 0.4624980390071869
acc_val: 0.7111
Epoch 170, training loss: 0.42409172654151917
acc_val: 0.7222
Epoch 180, training loss: 0.4264581799507141
acc_val: 0.7185
Epoch 190, training loss: 0.3937922418117523
acc_val: 0.7296
=== picking the best model according to the performance on validation ===
Training encoder Finished!
Total time elapsed: 3.2186s
Encoder CA on clean test nodes: 0.7926
[4 1 1 ... 6 4 4]
Epoch 0, loss_inner: 1.94549, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.2107, ASR_train_attach: 0.0000, ASR_train_outter: 0.0000
Epoch 10, loss_inner: 1.71860, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.3198, ASR_train_attach: 0.0000, ASR_train_outter: 0.0000
Epoch 20, loss_inner: 1.54979, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.3475, ASR_train_attach: 0.0000, ASR_train_outter: 0.0206
Epoch 30, loss_inner: 1.37047, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.5675, ASR_train_attach: 0.0476, ASR_train_outter: 0.0919
Epoch 40, loss_inner: 1.18358, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.7671, ASR_train_attach: 0.3333, ASR_train_outter: 0.2814
Epoch 50, loss_inner: 1.00960, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.8152, ASR_train_attach: 0.3333, ASR_train_outter: 0.3189
Epoch 60, loss_inner: 0.86510, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.8262, ASR_train_attach: 0.3810, ASR_train_outter: 0.3602
Epoch 70, loss_inner: 0.74589, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.8614, ASR_train_attach: 0.3810, ASR_train_outter: 0.3546
Epoch 80, loss_inner: 0.65217, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.8835, ASR_train_attach: 0.4286, ASR_train_outter: 0.3527
Epoch 90, loss_inner: 0.58323, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.8965, ASR_train_attach: 0.3810, ASR_train_outter: 0.3340
Epoch 100, loss_inner: 0.52928, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9168, ASR_train_attach: 0.3810, ASR_train_outter: 0.3640
Epoch 110, loss_inner: 0.48775, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9261, ASR_train_attach: 0.4286, ASR_train_outter: 0.3490
Epoch 120, loss_inner: 0.45631, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9335, ASR_train_attach: 0.4286, ASR_train_outter: 0.3677
Epoch 130, loss_inner: 0.42918, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9390, ASR_train_attach: 0.4286, ASR_train_outter: 0.3265
Epoch 140, loss_inner: 0.40812, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9427, ASR_train_attach: 0.5238, ASR_train_outter: 0.3546
Epoch 150, loss_inner: 0.38906, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9445, ASR_train_attach: 0.5714, ASR_train_outter: 0.3208
Epoch 160, loss_inner: 0.37607, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9445, ASR_train_attach: 0.5238, ASR_train_outter: 0.3640
Epoch 170, loss_inner: 0.36257, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9538, ASR_train_attach: 0.5238, ASR_train_outter: 0.3546
Epoch 180, loss_inner: 0.35062, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9556, ASR_train_attach: 0.5238, ASR_train_outter: 0.3396
Epoch 190, loss_inner: 0.34052, loss_target: 0.00000, homo loss: 0.00000 
acc_train_clean: 0.9538, ASR_train_attach: 0.5238, ASR_train_outter: 0.3246
precent of left attach nodes: 1.000
target class rate on Vs: 0.4762
accuracy on clean test nodes: 0.8259
ASR: 0.3210
CA: 0.8259
