nohup: ignoring input
Namespace(clean_test_nodes_num=200, cuda=True, dataset='cora', debug=True, defense_mode='isolate', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=0.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.1, seed=10, target_class=0, target_test_nodes_num=200, test_model='GraphSage', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.8360
Benign CA on clean test nodes: 0.7800
2708
200
Epoch 0, training loss: 1.9394763708114624
acc_train_clean: 0.1768, acc_train_attach: 0.0000
Epoch 10, training loss: 0.5679745674133301
acc_train_clean: 0.9071, acc_train_attach: 1.0000
Epoch 20, training loss: 0.20934630930423737
acc_train_clean: 0.9411, acc_train_attach: 1.0000
Epoch 30, training loss: 0.12698887288570404
acc_train_clean: 0.9643, acc_train_attach: 1.0000
Epoch 40, training loss: 0.09730815142393112
acc_train_clean: 0.9750, acc_train_attach: 1.0000
Epoch 50, training loss: 0.06966763734817505
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 60, training loss: 0.09380032867193222
acc_train_clean: 0.9857, acc_train_attach: 0.9412
Epoch 70, training loss: 0.07424839586019516
acc_train_clean: 0.9821, acc_train_attach: 1.0000
Epoch 80, training loss: 0.07422426342964172
acc_train_clean: 0.9857, acc_train_attach: 0.8824
Epoch 90, training loss: 0.058609556406736374
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 100, training loss: 0.06764665991067886
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 110, training loss: 0.05955522507429123
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 120, training loss: 0.055075738579034805
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 130, training loss: 0.0576942153275013
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 140, training loss: 0.05834542587399483
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 150, training loss: 0.0625474750995636
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 160, training loss: 0.057091210037469864
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 170, training loss: 0.0467165932059288
acc_train_clean: 0.9911, acc_train_attach: 1.0000
Epoch 180, training loss: 0.05462849885225296
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 190, training loss: 0.04418497160077095
acc_train_clean: 0.9911, acc_train_attach: 1.0000
tensor([[   2, 1986],
        [   9, 2614],
        [  12, 1001],
        ...,
        [2750, 1894],
        [2753, 2502],
        [2756,  213]])
577
314
4306 2914
set()
=== training gcn model ===
Epoch 0, training loss: 1.9563000202178955
acc_val: 0.3675
Epoch 10, training loss: 0.27094656229019165
acc_val: 0.7000
Epoch 20, training loss: 0.07898629456758499
acc_val: 0.6875
Epoch 30, training loss: 0.04177899658679962
acc_val: 0.6775
Epoch 40, training loss: 0.028460251167416573
acc_val: 0.6750
Epoch 50, training loss: 0.017735790461301804
acc_val: 0.6850
Epoch 60, training loss: 0.019586391746997833
acc_val: 0.7000
Epoch 70, training loss: 0.029815196990966797
acc_val: 0.6900
Epoch 80, training loss: 0.021787501871585846
acc_val: 0.7075
Epoch 90, training loss: 0.02144002355635166
acc_val: 0.6875
Epoch 100, training loss: 0.03237851709127426
acc_val: 0.7025
Epoch 110, training loss: 0.019167887046933174
acc_val: 0.7275
Epoch 120, training loss: 0.01706804521381855
acc_val: 0.7075
Epoch 130, training loss: 0.027644291520118713
acc_val: 0.7225
Epoch 140, training loss: 0.019764332100749016
acc_val: 0.7300
Epoch 150, training loss: 0.02188340201973915
acc_val: 0.7225
Epoch 160, training loss: 0.021861566230654716
acc_val: 0.7150
Epoch 170, training loss: 0.0194404236972332
acc_val: 0.7225
Epoch 180, training loss: 0.020373160019516945
acc_val: 0.7250
Epoch 190, training loss: 0.025017881765961647
acc_val: 0.7100
=== picking the best model according to the performance on validation ===
target class rate on Vs: 0.1765
accuracy on clean test nodes: 0.7750
ASR: 0.0500
CA: 0.7150
