nohup: ignoring input
Namespace(clean_test_nodes_num=200, cuda=True, dataset='cora', debug=True, defense_mode='none', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.1, seed=10, target_class=0, target_test_nodes_num=200, test_model='GCN', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.8360
Benign CA on clean test nodes: 0.7800
2708
200
Epoch 0, training loss: 1.9394763708114624
acc_train_clean: 0.1768, acc_train_attach: 0.0000
Epoch 10, training loss: 0.5679745674133301
acc_train_clean: 0.9071, acc_train_attach: 1.0000
Epoch 20, training loss: 0.20934629440307617
acc_train_clean: 0.9411, acc_train_attach: 1.0000
Epoch 30, training loss: 0.12698887288570404
acc_train_clean: 0.9643, acc_train_attach: 1.0000
Epoch 40, training loss: 0.09730815887451172
acc_train_clean: 0.9750, acc_train_attach: 1.0000
Epoch 50, training loss: 0.06966762989759445
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 60, training loss: 0.09380032122135162
acc_train_clean: 0.9857, acc_train_attach: 0.9412
Epoch 70, training loss: 0.07424838095903397
acc_train_clean: 0.9821, acc_train_attach: 1.0000
Epoch 80, training loss: 0.07422426342964172
acc_train_clean: 0.9857, acc_train_attach: 0.8824
Epoch 90, training loss: 0.058609556406736374
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 100, training loss: 0.06764666736125946
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 110, training loss: 0.059555184096097946
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 120, training loss: 0.05507583171129227
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 130, training loss: 0.057695094496011734
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 140, training loss: 0.05834343284368515
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 150, training loss: 0.06265104562044144
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 160, training loss: 0.05709415674209595
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 170, training loss: 0.04663163796067238
acc_train_clean: 0.9911, acc_train_attach: 1.0000
Epoch 180, training loss: 0.05553700029850006
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 190, training loss: 0.04401016980409622
acc_train_clean: 0.9911, acc_train_attach: 1.0000
577
577
4306 4306
{2242, 1506, 2436, 1157, 1734, 2276, 1029, 2089, 1894, 2502, 430, 1743, 1969, 213, 1591, 183, 2204}
=== training gcn model ===
Epoch 0, training loss: 1.9491996765136719
acc_val: 0.3575
Epoch 10, training loss: 0.5982194542884827
acc_val: 0.7950
Epoch 20, training loss: 0.21813170611858368
acc_val: 0.8025
Epoch 30, training loss: 0.1146034374833107
acc_val: 0.8050
Epoch 40, training loss: 0.08913102000951767
acc_val: 0.7950
Epoch 50, training loss: 0.07728193700313568
acc_val: 0.7900
Epoch 60, training loss: 0.09040861576795578
acc_val: 0.7925
Epoch 70, training loss: 0.06813251227140427
acc_val: 0.8025
Epoch 80, training loss: 0.07144561409950256
acc_val: 0.7925
Epoch 90, training loss: 0.0625450387597084
acc_val: 0.8125
Epoch 100, training loss: 0.05967774614691734
acc_val: 0.8050
Epoch 110, training loss: 0.06764129549264908
acc_val: 0.7975
Epoch 120, training loss: 0.056715287268161774
acc_val: 0.7950
Epoch 130, training loss: 0.06126968935132027
acc_val: 0.8050
Epoch 140, training loss: 0.06359449028968811
acc_val: 0.7950
Epoch 150, training loss: 0.051057446748018265
acc_val: 0.7975
Epoch 160, training loss: 0.05205756053328514
acc_val: 0.8000
Epoch 170, training loss: 0.047666192054748535
acc_val: 0.7950
Epoch 180, training loss: 0.05067694932222366
acc_val: 0.7975
Epoch 190, training loss: 0.05032442882657051
acc_val: 0.8000
=== picking the best model according to the performance on validation ===
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.8200
ASR: 0.9900
CA: 0.8050
