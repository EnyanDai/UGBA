nohup: ignoring input
Namespace(clean_test_nodes_num=200, cuda=True, dataset='pubmed', debug=True, defense_mode='prune', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=1.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.15, seed=10, target_class=0, target_test_nodes_num=200, test_model='GraphSage', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.8110
Benign CA on clean test nodes: 0.7400
19717
200
tensor(1.0985, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(224.4008, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 0, training loss: 1.098490834236145
acc_train_clean: 0.2083, acc_train_attach: 0.3155
tensor(1.0689, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(224.4008, device='cuda:5', grad_fn=<MulBackward0>)
tensor(1.0376, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(224.4008, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6292, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(135.0875, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6320, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6368, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6205, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6270, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6094, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6098, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.6021, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 10, training loss: 0.6021488904953003
acc_train_clean: 0.3417, acc_train_attach: 1.0000
tensor(0.5978, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5941, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5909, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5850, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5755, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5628, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5649, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4230, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5495, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.4155, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5461, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(134.0076, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 20, training loss: 0.5461322665214539
acc_train_clean: 0.4708, acc_train_attach: 1.0000
tensor(0.5385, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(133.8110, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5369, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(132.8424, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5305, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(132.6205, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5241, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(133.4531, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5175, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(133.6751, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.5065, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(133.7466, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4936, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(132.4846, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4897, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.2220, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4872, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(130.7412, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4759, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(130.7652, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 30, training loss: 0.475903183221817
acc_train_clean: 0.7583, acc_train_attach: 1.0000
tensor(0.4726, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.4144, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4773, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.8127, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4604, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.7422, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4575, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(131.6431, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4495, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(130.4086, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4511, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(128.7410, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4446, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(128.3509, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4343, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.4064, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4151, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.2086, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4085, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(126.0408, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 40, training loss: 0.4084673523902893
acc_train_clean: 0.8333, acc_train_attach: 1.0000
tensor(0.3963, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(125.9906, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3954, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(125.6415, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4121, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(126.5598, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.4060, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.6414, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3903, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.2673, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3907, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(127.4493, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3954, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(125.3996, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3815, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(124.3683, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3547, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(123.6217, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3666, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.5327, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 50, training loss: 0.3665613532066345
acc_train_clean: 0.8375, acc_train_attach: 1.0000
tensor(0.3600, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(121.8507, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3551, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.4342, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3686, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.6879, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3682, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(123.2874, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3374, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(124.8525, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3218, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(123.6914, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3175, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.4328, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3162, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(122.0106, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3140, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(120.6996, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3075, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(120.9894, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 60, training loss: 0.3074893355369568
acc_train_clean: 0.8583, acc_train_attach: 0.9947
tensor(0.2941, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(120.9892, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3096, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(120.4257, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3183, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.5174, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3087, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.4052, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3168, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(117.5866, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.3052, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(117.9509, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2901, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.2550, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2874, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.2966, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2814, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(117.7075, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2824, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(118.4017, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 70, training loss: 0.28237074613571167
acc_train_clean: 0.8500, acc_train_attach: 1.0000
tensor(0.2834, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(117.6927, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2787, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(116.7205, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2593, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(116.7876, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2597, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(116.5502, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2607, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.9126, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2710, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.4094, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2782, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.5491, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2512, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.2541, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2748, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.6201, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2510, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.6899, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 80, training loss: 0.25101253390312195
acc_train_clean: 0.8708, acc_train_attach: 1.0000
tensor(0.2551, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(115.6782, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2440, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.4544, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2590, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.4119, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2378, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.6273, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2379, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.0707, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2239, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.4620, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2441, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.9126, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2268, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.6817, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2253, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(114.2912, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2291, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.2359, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 90, training loss: 0.22907328605651855
acc_train_clean: 0.9042, acc_train_attach: 0.9947
tensor(0.2246, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.1004, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2378, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.2267, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2169, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.3369, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2086, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.8789, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2474, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.3719, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2128, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.7989, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2111, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.8709, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2235, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.5834, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2145, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(112.5195, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2229, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(113.0320, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 100, training loss: 0.22294555604457855
acc_train_clean: 0.9125, acc_train_attach: 1.0000
tensor(0.2256, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(111.9687, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2237, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.9863, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2121, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.9120, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2167, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(111.0865, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2241, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(111.4034, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2112, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.6195, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2108, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.7957, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2056, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.8516, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2044, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(111.1936, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2013, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.6687, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 110, training loss: 0.20128066837787628
acc_train_clean: 0.9208, acc_train_attach: 1.0000
tensor(0.1967, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.6560, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1976, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.0004, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2069, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.6582, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1933, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.4336, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2077, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.5430, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2042, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.5430, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1969, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.6781, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1931, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.6655, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1958, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.0235, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.2015, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(110.4410, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 120, training loss: 0.20148111879825592
acc_train_clean: 0.9250, acc_train_attach: 1.0000
tensor(0.2026, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.6699, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1840, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.3282, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1911, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.4895, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1837, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.9210, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1856, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.9183, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1882, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.3562, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1759, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.9189, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1862, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.9681, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1847, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.7261, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1834, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.6098, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 130, training loss: 0.18336351215839386
acc_train_clean: 0.9500, acc_train_attach: 0.9947
tensor(0.2035, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(109.5935, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1859, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.6567, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1964, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.8809, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1776, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.8314, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1901, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.5339, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1878, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.0937, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1817, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.6162, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1823, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.1650, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1750, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.8322, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1671, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.9663, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 140, training loss: 0.1671377718448639
acc_train_clean: 0.9625, acc_train_attach: 1.0000
tensor(0.1696, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.6521, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1661, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4455, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1746, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.2876, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1870, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2810, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1741, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.0432, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1752, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2454, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1690, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.6286, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1750, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4332, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1627, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.5529, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1643, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.8685, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 150, training loss: 0.1642853021621704
acc_train_clean: 0.9417, acc_train_attach: 1.0000
tensor(0.1659, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.0667, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1658, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(108.2617, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1604, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.5098, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1718, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.7741, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1604, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.5572, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1641, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.1464, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1715, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.5042, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1653, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2338, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1593, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.1755, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1618, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2876, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 160, training loss: 0.16178461909294128
acc_train_clean: 0.9458, acc_train_attach: 1.0000
tensor(0.1631, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.8004, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1570, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.1826, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1619, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.4583, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1561, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.6561, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1686, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2695, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1533, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.2176, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1541, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.7847, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1500, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.9434, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1625, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.4579, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1524, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.7972, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 170, training loss: 0.15239152312278748
acc_train_clean: 0.9750, acc_train_attach: 0.9947
tensor(0.1482, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3002, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1562, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3980, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1663, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3471, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1596, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.0425, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1506, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(107.1711, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1568, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.5540, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1544, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.5639, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1631, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.4255, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1731, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.8068, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1634, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.9154, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 180, training loss: 0.1633990854024887
acc_train_clean: 0.9625, acc_train_attach: 1.0000
tensor(0.1513, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.6110, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1548, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.7607, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1561, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.6932, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1529, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3976, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1447, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.4557, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1487, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.1250, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1456, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.8703, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1507, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.9536, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1470, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.2606, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1509, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.1292, device='cuda:5', grad_fn=<MulBackward0>)
Epoch 190, training loss: 0.15087451040744781
acc_train_clean: 0.9500, acc_train_attach: 0.9947
tensor(0.1487, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.5263, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1547, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.6715, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1528, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3292, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1444, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.9875, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1357, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.3820, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1478, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.2136, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1425, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.5038, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1536, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(105.8733, device='cuda:5', grad_fn=<MulBackward0>)
tensor(0.1574, device='cuda:5', grad_fn=<NllLossBackward0>) tensor(106.2755, device='cuda:5', grad_fn=<MulBackward0>)
427
427
81052 57910
{11777, 10246, 7175, 17928, 15370, 13326, 12816, 17914, 2067, 15892, 1530, 3606, 10776, 15385, 17438, 1566, 12833, 16419, 18983, 13352, 4650, 45, 15919, 4145, 8753, 8755, 6201, 9785, 12864, 64, 10307, 4676, 7754, 3147, 16460, 19533, 9294, 1101, 4176, 7245, 19539, 13395, 4179, 4692, 10839, 15448, 3680, 3681, 3170, 7274, 9324, 11373, 14454, 19584, 128, 12419, 10884, 4742, 2183, 11400, 6283, 1680, 18066, 6805, 6294, 5277, 11935, 15009, 10408, 16552, 19122, 8371, 14005, 14011, 19132, 8905, 9930, 13517, 7374, 12494, 18642, 5332, 7384, 8926, 6369, 226, 9445, 235, 4849, 753, 9460, 7414, 10492, 11007, 18176, 16130, 3845, 14086, 16645, 9993, 1296, 7959, 15640, 15132, 18722, 15145, 8494, 7473, 2354, 5427, 6964, 13621, 6455, 1855, 4933, 8522, 15178, 14156, 11084, 18250, 16717, 9043, 12627, 16728, 9563, 12637, 8547, 5987, 16741, 2917, 4970, 18799, 14193, 17778, 3955, 17266, 374, 14713, 6012, 2941, 16256, 12164, 6532, 3974, 18311, 8588, 19341, 19350, 17303, 3481, 7580, 17824, 14753, 8609, 17316, 6565, 7592, 6570, 17835, 18348, 2478, 6575, 9141, 14263, 14780, 12221, 15294, 8646, 17865, 6606, 3541, 2520, 9181, 5092, 6628, 18918, 11751, 15848, 15845, 4076, 4589, 2543, 5103, 10226, 2554, 6651, 3068}
=== training gcn model ===
Epoch 0, training loss: 1.1579872369766235
acc_val: 0.4325
Epoch 10, training loss: 0.5980775356292725
acc_val: 0.2925
Epoch 20, training loss: 0.5103546977043152
acc_val: 0.6025
Epoch 30, training loss: 0.3986726701259613
acc_val: 0.6625
Epoch 40, training loss: 0.3140425384044647
acc_val: 0.7250
Epoch 50, training loss: 0.2382843792438507
acc_val: 0.7400
Epoch 60, training loss: 0.1773614138364792
acc_val: 0.7425
Epoch 70, training loss: 0.13111147284507751
acc_val: 0.7500
Epoch 80, training loss: 0.1123010441660881
acc_val: 0.7500
Epoch 90, training loss: 0.09587405622005463
acc_val: 0.7500
Epoch 100, training loss: 0.08951905369758606
acc_val: 0.7525
Epoch 110, training loss: 0.0795639380812645
acc_val: 0.7425
Epoch 120, training loss: 0.07613050937652588
acc_val: 0.7400
Epoch 130, training loss: 0.07170074433088303
acc_val: 0.7525
Epoch 140, training loss: 0.06790075451135635
acc_val: 0.7475
Epoch 150, training loss: 0.053349003195762634
acc_val: 0.7475
Epoch 160, training loss: 0.05743197724223137
acc_val: 0.7500
Epoch 170, training loss: 0.05365278944373131
acc_val: 0.7550
Epoch 180, training loss: 0.05275796726346016
acc_val: 0.7525
Epoch 190, training loss: 0.05223800987005234
acc_val: 0.7475
=== picking the best model according to the performance on validation ===
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.7550
ASR: 0.9950
CA: 0.7300
