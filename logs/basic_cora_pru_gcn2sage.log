nohup: ignoring input
Namespace(clean_test_nodes_num=200, cuda=True, dataset='cora', debug=True, defense_mode='prune', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=0.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.1, seed=10, target_class=0, target_test_nodes_num=200, test_model='GraphSage', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.8360
Benign CA on clean test nodes: 0.7800
2708
200
Epoch 0, training loss: 1.9394763708114624
acc_train_clean: 0.1768, acc_train_attach: 0.0000
Epoch 10, training loss: 0.5679745078086853
acc_train_clean: 0.9071, acc_train_attach: 1.0000
Epoch 20, training loss: 0.20934629440307617
acc_train_clean: 0.9411, acc_train_attach: 1.0000
Epoch 30, training loss: 0.12698887288570404
acc_train_clean: 0.9643, acc_train_attach: 1.0000
Epoch 40, training loss: 0.09730815887451172
acc_train_clean: 0.9750, acc_train_attach: 1.0000
Epoch 50, training loss: 0.06966762989759445
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 60, training loss: 0.09380032122135162
acc_train_clean: 0.9857, acc_train_attach: 0.9412
Epoch 70, training loss: 0.07424838840961456
acc_train_clean: 0.9821, acc_train_attach: 1.0000
Epoch 80, training loss: 0.07422426342964172
acc_train_clean: 0.9857, acc_train_attach: 0.8824
Epoch 90, training loss: 0.058609556406736374
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 100, training loss: 0.06764667481184006
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 110, training loss: 0.05955521762371063
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 120, training loss: 0.05507583171129227
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 130, training loss: 0.057695139199495316
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 140, training loss: 0.05834338814020157
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 150, training loss: 0.06266994774341583
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 160, training loss: 0.057101111859083176
acc_train_clean: 0.9893, acc_train_attach: 1.0000
Epoch 170, training loss: 0.04655713960528374
acc_train_clean: 0.9911, acc_train_attach: 1.0000
Epoch 180, training loss: 0.058365873992443085
acc_train_clean: 0.9857, acc_train_attach: 1.0000
Epoch 190, training loss: 0.044939327985048294
acc_train_clean: 0.9911, acc_train_attach: 1.0000
577
577
4306 2914
{2242, 1506, 2436, 1157, 1734, 2276, 1029, 2089, 1894, 2502, 430, 1743, 1969, 213, 1591, 183, 2204}
=== training gcn model ===
Epoch 0, training loss: 1.9514496326446533
acc_val: 0.3200
Epoch 10, training loss: 0.37449175119400024
acc_val: 0.7475
Epoch 20, training loss: 0.137416273355484
acc_val: 0.7250
Epoch 30, training loss: 0.05930260941386223
acc_val: 0.7350
Epoch 40, training loss: 0.03475140407681465
acc_val: 0.7175
Epoch 50, training loss: 0.036128316074609756
acc_val: 0.7300
Epoch 60, training loss: 0.04254629835486412
acc_val: 0.7225
Epoch 70, training loss: 0.04129263386130333
acc_val: 0.7350
Epoch 80, training loss: 0.03396955877542496
acc_val: 0.7275
Epoch 90, training loss: 0.033559542149305344
acc_val: 0.7350
Epoch 100, training loss: 0.034640487283468246
acc_val: 0.7275
Epoch 110, training loss: 0.031908296048641205
acc_val: 0.7275
Epoch 120, training loss: 0.027469202876091003
acc_val: 0.7300
Epoch 130, training loss: 0.033216726034879684
acc_val: 0.7250
Epoch 140, training loss: 0.031165657564997673
acc_val: 0.7350
Epoch 150, training loss: 0.03109843283891678
acc_val: 0.7375
Epoch 160, training loss: 0.035439521074295044
acc_val: 0.7375
Epoch 170, training loss: 0.03135873004794121
acc_val: 0.7350
Epoch 180, training loss: 0.025817256420850754
acc_val: 0.7400
Epoch 190, training loss: 0.030287066474556923
acc_val: 0.7250
=== picking the best model according to the performance on validation ===
target class rate on Vs: 0.7647
accuracy on clean test nodes: 0.7500
ASR: 0.0600
CA: 0.7250
