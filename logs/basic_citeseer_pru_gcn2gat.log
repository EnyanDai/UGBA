nohup: ignoring input
/home/project-graph-backdoor/Backdoor/models/GAT.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.labels = torch.tensor(labels, dtype=torch.long)
Namespace(clean_test_nodes_num=200, cuda=True, dataset='citeseer', debug=True, defense_mode='prune', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=0.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.15, seed=10, target_class=0, target_test_nodes_num=200, test_model='GAT', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.7100
Benign CA on clean test nodes: 0.6450
3327
200
Epoch 0, training loss: 1.8009929656982422
acc_train_clean: 0.1479, acc_train_attach: 0.1304
Epoch 10, training loss: 0.2316441386938095
acc_train_clean: 0.9437, acc_train_attach: 1.0000
Epoch 20, training loss: 0.07828577607870102
acc_train_clean: 0.9771, acc_train_attach: 1.0000
Epoch 30, training loss: 0.0522322840988636
acc_train_clean: 0.9854, acc_train_attach: 1.0000
Epoch 40, training loss: 0.0490339919924736
acc_train_clean: 0.9833, acc_train_attach: 1.0000
Epoch 50, training loss: 0.05806906148791313
acc_train_clean: 0.9854, acc_train_attach: 1.0000
Epoch 60, training loss: 0.04994307458400726
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 70, training loss: 0.061829689890146255
acc_train_clean: 0.9875, acc_train_attach: 0.9565
Epoch 80, training loss: 0.07196313887834549
acc_train_clean: 0.9792, acc_train_attach: 0.9565
Epoch 90, training loss: 0.047797586768865585
acc_train_clean: 0.9938, acc_train_attach: 0.9565
Epoch 100, training loss: 0.04624990373849869
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 110, training loss: 0.04627414047718048
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 120, training loss: 0.04746882617473602
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 130, training loss: 0.035048920661211014
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 140, training loss: 0.039583176374435425
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 150, training loss: 0.03462143614888191
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 160, training loss: 0.056822698563337326
acc_train_clean: 0.9812, acc_train_attach: 1.0000
Epoch 170, training loss: 0.03016921505331993
acc_train_clean: 0.9938, acc_train_attach: 1.0000
Epoch 180, training loss: 0.03511510789394379
acc_train_clean: 0.9917, acc_train_attach: 1.0000
Epoch 190, training loss: 0.038573797792196274
acc_train_clean: 0.9917, acc_train_attach: 1.0000
503
503
4454 2342
{1152, 2062, 1945, 3239, 1461, 57, 2371, 195, 2118, 1478, 1481, 2506, 1741, 1366, 3031, 1115, 3038, 3294, 350, 2537, 1778, 499, 1785}
=== training gcn model ===
Epoch 0, training loss: 1.8576894998550415
acc_val: 0.4800
Epoch 10, training loss: 0.8989289999008179
acc_val: 0.6150
Epoch 20, training loss: 0.749556839466095
acc_val: 0.5925
Epoch 30, training loss: 0.7166502475738525
acc_val: 0.6175
Epoch 40, training loss: 0.7070106863975525
acc_val: 0.5925
Epoch 50, training loss: 0.7696986794471741
acc_val: 0.6250
Epoch 60, training loss: 0.7026280760765076
acc_val: 0.6300
Epoch 70, training loss: 0.6844756603240967
acc_val: 0.5925
Epoch 80, training loss: 0.6885867118835449
acc_val: 0.6175
Epoch 90, training loss: 0.700038492679596
acc_val: 0.6075
Epoch 100, training loss: 0.746478796005249
acc_val: 0.5950
Epoch 110, training loss: 0.6872718930244446
acc_val: 0.5950
Epoch 120, training loss: 0.738810658454895
acc_val: 0.6025
Epoch 130, training loss: 0.7796167731285095
acc_val: 0.6075
Epoch 140, training loss: 0.6695414781570435
acc_val: 0.6025
Epoch 150, training loss: 0.6863705515861511
acc_val: 0.6075
Epoch 160, training loss: 0.7209998965263367
acc_val: 0.6000
Epoch 170, training loss: 0.7470039129257202
acc_val: 0.6125
Epoch 180, training loss: 0.6941969394683838
acc_val: 0.6025
Epoch 190, training loss: 0.6653808951377869
acc_val: 0.6100
=== picking the best model according to the performance on validation ===
target class rate on Vs: 0.5652
accuracy on clean test nodes: 0.7400
ASR: 0.0250
CA: 0.7200
