nohup: ignoring input
Namespace(clean_test_nodes_num=200, cuda=True, dataset='citeseer', debug=True, defense_mode='prune', device_id=5, dropout=0.5, epochs=200, hidden=32, homo_boost_thrd=0.6, homo_loss_weight=0.0, load_benign_model=True, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.15, seed=10, target_class=0, target_test_nodes_num=200, test_model='GraphSage', thrd=0.5, trigger_size=3, trojan_epochs=200, vs_ratio=0.01, weight_decay=0.0005)
Loading benign GCN model Finished!
Benign CA: 0.7100
Benign CA on clean test nodes: 0.6450
3327
200
Epoch 0, training loss: 1.8009929656982422
acc_train_clean: 0.1479, acc_train_attach: 0.1304
Epoch 10, training loss: 0.2316441386938095
acc_train_clean: 0.9437, acc_train_attach: 1.0000
Epoch 20, training loss: 0.07828578352928162
acc_train_clean: 0.9771, acc_train_attach: 1.0000
Epoch 30, training loss: 0.0522325299680233
acc_train_clean: 0.9854, acc_train_attach: 1.0000
Epoch 40, training loss: 0.04903392121195793
acc_train_clean: 0.9833, acc_train_attach: 1.0000
Epoch 50, training loss: 0.058110613375902176
acc_train_clean: 0.9833, acc_train_attach: 1.0000
Epoch 60, training loss: 0.04916129633784294
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 70, training loss: 0.06511376798152924
acc_train_clean: 0.9896, acc_train_attach: 0.9565
Epoch 80, training loss: 0.05483020469546318
acc_train_clean: 0.9833, acc_train_attach: 0.9565
Epoch 90, training loss: 0.05030299350619316
acc_train_clean: 0.9917, acc_train_attach: 1.0000
Epoch 100, training loss: 0.04470878839492798
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 110, training loss: 0.045866988599300385
acc_train_clean: 0.9854, acc_train_attach: 1.0000
Epoch 120, training loss: 0.04641290381550789
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 130, training loss: 0.03752187266945839
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 140, training loss: 0.03886596858501434
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 150, training loss: 0.03570767119526863
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 160, training loss: 0.03964627906680107
acc_train_clean: 0.9896, acc_train_attach: 1.0000
Epoch 170, training loss: 0.030037863180041313
acc_train_clean: 0.9938, acc_train_attach: 1.0000
Epoch 180, training loss: 0.039489928632974625
acc_train_clean: 0.9875, acc_train_attach: 1.0000
Epoch 190, training loss: 0.037984151393175125
acc_train_clean: 0.9917, acc_train_attach: 1.0000
503
503
4454 2342
{1152, 2062, 1945, 3239, 1461, 57, 2371, 195, 2118, 1478, 1481, 2506, 1741, 1366, 3031, 1115, 3038, 3294, 350, 2537, 1778, 499, 1785}
=== training gcn model ===
Epoch 0, training loss: 1.7902586460113525
acc_val: 0.1350
Epoch 10, training loss: 0.25014612078666687
acc_val: 0.6175
Epoch 20, training loss: 0.0742451548576355
acc_val: 0.5900
Epoch 30, training loss: 0.052643071860075
acc_val: 0.5900
Epoch 40, training loss: 0.03241947665810585
acc_val: 0.5950
Epoch 50, training loss: 0.04270123690366745
acc_val: 0.6125
Epoch 60, training loss: 0.03483162820339203
acc_val: 0.5975
Epoch 70, training loss: 0.03484239801764488
acc_val: 0.6250
Epoch 80, training loss: 0.03139221668243408
acc_val: 0.6200
Epoch 90, training loss: 0.03671957924962044
acc_val: 0.6175
Epoch 100, training loss: 0.03590628132224083
acc_val: 0.6200
Epoch 110, training loss: 0.028088554739952087
acc_val: 0.6250
Epoch 120, training loss: 0.022891856729984283
acc_val: 0.6300
Epoch 130, training loss: 0.027635253965854645
acc_val: 0.6400
Epoch 140, training loss: 0.030992265790700912
acc_val: 0.6125
Epoch 150, training loss: 0.03556445240974426
acc_val: 0.6400
Epoch 160, training loss: 0.02114565670490265
acc_val: 0.6475
Epoch 170, training loss: 0.03298664465546608
acc_val: 0.6350
Epoch 180, training loss: 0.026976196095347404
acc_val: 0.6400
Epoch 190, training loss: 0.03279649838805199
acc_val: 0.6350
=== picking the best model according to the performance on validation ===
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.6800
ASR: 0.0700
CA: 0.6400
