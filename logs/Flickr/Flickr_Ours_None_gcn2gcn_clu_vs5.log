nohup: ignoring input
Namespace(cuda=True, dataset='Flickr', debug=True, defense_mode='none', device_id=1, dis_weight=0.0, dropout=0.5, epochs=200, evaluate_mode='overall', hidden=64, homo_boost_thrd=0.5, homo_loss_weight=1.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.15, seed=11, selection_method='cluster_degree', target_class=0, target_loss_weight=1, test_model='GCN', thrd=0.5, train_lr=0.02, trigger_size=3, trojan_epochs=200, use_vs_number=True, vs_number=5, vs_ratio=0, weight_decay=0.0005)
Length of training set: 17850
Training benign model Finished!
Total time elapsed: 10.6894s
Benign CA: 0.4548
#Attach Nodes:5
Length of training set: 17850
=== training gcn model ===
Epoch 0, training loss: 1.980782389640808
acc_val: 0.2613
Epoch 10, training loss: 1.625368356704712
acc_val: 0.4119
Epoch 20, training loss: 1.5911859273910522
acc_val: 0.4119
Epoch 30, training loss: 1.5817729234695435
acc_val: 0.4119
Epoch 40, training loss: 1.5776357650756836
acc_val: 0.4124
Epoch 50, training loss: 1.5716015100479126
acc_val: 0.4165
Epoch 60, training loss: 1.5620604753494263
acc_val: 0.4182
Epoch 70, training loss: 1.5458614826202393
acc_val: 0.4496
Epoch 80, training loss: 1.524265170097351
acc_val: 0.4594
Epoch 90, training loss: 1.5199640989303589
acc_val: 0.4728
Epoch 100, training loss: 1.5116163492202759
acc_val: 0.4817
Epoch 110, training loss: 1.5087916851043701
acc_val: 0.4745
Epoch 120, training loss: 1.5027406215667725
acc_val: 0.4804
Epoch 130, training loss: 1.511884331703186
acc_val: 0.4867
Epoch 140, training loss: 1.505772590637207
acc_val: 0.4761
Epoch 150, training loss: 1.5099865198135376
acc_val: 0.4903
Epoch 160, training loss: 1.500899076461792
acc_val: 0.4914
Epoch 170, training loss: 1.4952226877212524
acc_val: 0.4925
Epoch 180, training loss: 1.4914900064468384
acc_val: 0.4895
Epoch 190, training loss: 1.5069328546524048
acc_val: 0.4949
=== picking the best model according to the performance on validation ===
Training encoder Finished!
Total time elapsed: 9.4219s
Encoder CA on clean test nodes: 0.4964
idx_sing_class []
idx_sing_class []
idx_sing_class []
idx_sing_class [    2     3     5 ... 89226 89246 89247]
each_class_size 0
y_pred [1 1 1 ... 1 1 0]
node_idxs [32769     2 65544 ... 65528 32761 32766]
selected_nodes [25889 47421 44860 ... 17801 23557    50] [25889 47421 44860 ... 17801 23557    50]
idx_sing_class []
idx_sing_class [    0     1     4 ... 89245 89248 89249]
each_class_size 0
y_pred [1 0 1 ... 0 1 1]
node_idxs [    0     4    10 ... 89243 89248 89249]
selected_nodes [35842 59960 32852 ...    53   184   171] [35842 59960 32852 ...    53   184   171]
idx_attach: tensor([25889, 47421, 44860,  ...,    53,   184,   171], device='cuda:1')
Traceback (most recent call last):
  File "run_adaptive.py", line 189, in <module>
    model.fit(data.x, train_edge_index, None, data.y, idx_train,idx_attach, unlabeled_idx)
  File "/home/mfl5681/project-backdoor/Backdoor/models/backdoor.py", line 222, in fit
    idx_outter = torch.cat([idx_attach,idx_unlabeled[rs.choice(len(idx_unlabeled),size=512,replace=False)]])
  File "mtrand.pyx", line 909, in numpy.random.mtrand.RandomState.choice
ValueError: a must be greater than 0 unless no samples are taken
