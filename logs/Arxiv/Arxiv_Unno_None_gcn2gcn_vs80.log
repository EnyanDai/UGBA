nohup: ignoring input
Namespace(cuda=True, dataset='ogbn-arxiv', debug=True, defense_mode='none', device_id=0, dis_weight=1.0, dropout=0.5, epochs=200, evaluate_mode='1by1', hidden=32, homo_boost_thrd=0.8, homo_loss_weight=100.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.8, seed=10, selection_method='none', target_class=0, target_loss_weight=1, test_model='GCN', thrd=0.5, train_lr=0.01, trigger_size=3, trojan_epochs=400, use_vs_number=True, vs_number=80, vs_ratio=0, weight_decay=0.0005)
#Attach Nodes:80
idx_attach: tensor([151986, 162467,  44926,  23940,  72501,  13300,  22065, 147153,  79242,
        128143,  93465,  63507,  73972,  73044,  56937,  88754, 163842, 119362,
         54554,  33519,   8154,  16049, 113091, 156331,  35927, 152431,  38080,
        168947, 121840, 101165,  34467, 130677, 127703, 162722,   4875,  95491,
        148529,  78072, 126281,  59601,  54103, 107477,  51951,  10138,  10104,
         26393,  18876, 151911,  73699, 122090, 149541,   7918,  23625,  54054,
        165054,  90478, 130766, 106047,  62056, 152543, 100119,  62343, 119437,
        129228, 130514,  12459,  58483,  35161,  27651,  77539,  49360,  43087,
         51852,  84642, 162577, 108656,  81292,  49283,  70860,  49404],
       device='cuda:0')
Epoch 0, loss_inner: 3.74866, loss_target: 3.62606, homo loss: 0.80884 
acc_train_clean: 0.0089, ASR_train_attach: 0.0000, ASR_train_outter: 0.0000
Epoch 10, loss_inner: 3.01320, loss_target: 3.12172, homo loss: 0.00509 
acc_train_clean: 0.2616, ASR_train_attach: 0.0000, ASR_train_outter: 0.0000
Epoch 20, loss_inner: 2.76283, loss_target: 2.82720, homo loss: 0.00098 
acc_train_clean: 0.2817, ASR_train_attach: 0.0000, ASR_train_outter: 0.0000
Epoch 30, loss_inner: 2.47010, loss_target: 2.48668, homo loss: 0.00067 
acc_train_clean: 0.3676, ASR_train_attach: 0.0000, ASR_train_outter: 0.0000
Epoch 40, loss_inner: 2.17810, loss_target: 2.17298, homo loss: 0.00053 
acc_train_clean: 0.4428, ASR_train_attach: 0.0000, ASR_train_outter: 0.0000
Epoch 50, loss_inner: 1.92988, loss_target: 1.90188, homo loss: 0.00045 
acc_train_clean: 0.5058, ASR_train_attach: 0.7375, ASR_train_outter: 0.6166
Epoch 60, loss_inner: 1.73450, loss_target: 1.70472, homo loss: 0.00045 
acc_train_clean: 0.5418, ASR_train_attach: 0.9125, ASR_train_outter: 0.8733
Epoch 70, loss_inner: 1.59519, loss_target: 1.56896, homo loss: 0.00033 
acc_train_clean: 0.5735, ASR_train_attach: 0.9500, ASR_train_outter: 0.9071
Epoch 80, loss_inner: 1.49247, loss_target: 1.46984, homo loss: 0.00021 
acc_train_clean: 0.5956, ASR_train_attach: 0.9625, ASR_train_outter: 0.9223
Epoch 90, loss_inner: 1.41839, loss_target: 1.39709, homo loss: 0.00021 
acc_train_clean: 0.6094, ASR_train_attach: 0.9875, ASR_train_outter: 0.9561
Epoch 100, loss_inner: 1.36765, loss_target: 1.34816, homo loss: 0.00017 
acc_train_clean: 0.6197, ASR_train_attach: 0.9875, ASR_train_outter: 0.9595
Epoch 110, loss_inner: 1.33205, loss_target: 1.31369, homo loss: 0.00011 
acc_train_clean: 0.6247, ASR_train_attach: 0.9875, ASR_train_outter: 0.9544
Epoch 120, loss_inner: 1.30253, loss_target: 1.28419, homo loss: 0.00008 
acc_train_clean: 0.6301, ASR_train_attach: 0.9875, ASR_train_outter: 0.9595
Epoch 130, loss_inner: 1.27478, loss_target: 1.25719, homo loss: 0.00002 
acc_train_clean: 0.6359, ASR_train_attach: 0.9875, ASR_train_outter: 0.9611
Epoch 140, loss_inner: 1.25226, loss_target: 1.23512, homo loss: 0.00003 
acc_train_clean: 0.6413, ASR_train_attach: 0.9875, ASR_train_outter: 0.9611
Epoch 150, loss_inner: 1.23590, loss_target: 1.21948, homo loss: 0.00009 
acc_train_clean: 0.6444, ASR_train_attach: 0.9875, ASR_train_outter: 0.9628
Epoch 160, loss_inner: 1.22384, loss_target: 1.20718, homo loss: 0.00002 
acc_train_clean: 0.6458, ASR_train_attach: 1.0000, ASR_train_outter: 0.9764
Epoch 170, loss_inner: 1.21476, loss_target: 1.19799, homo loss: 0.00000 
acc_train_clean: 0.6480, ASR_train_attach: 1.0000, ASR_train_outter: 0.9831
Epoch 180, loss_inner: 1.20738, loss_target: 1.19076, homo loss: 0.00005 
acc_train_clean: 0.6497, ASR_train_attach: 1.0000, ASR_train_outter: 0.9814
Epoch 190, loss_inner: 1.20095, loss_target: 1.18502, homo loss: 0.00007 
acc_train_clean: 0.6506, ASR_train_attach: 0.9875, ASR_train_outter: 0.9831
Epoch 200, loss_inner: 1.19493, loss_target: 1.17833, homo loss: 0.00002 
acc_train_clean: 0.6529, ASR_train_attach: 1.0000, ASR_train_outter: 0.9916
Epoch 210, loss_inner: 1.18927, loss_target: 1.17271, homo loss: 0.00000 
acc_train_clean: 0.6540, ASR_train_attach: 1.0000, ASR_train_outter: 0.9899
Epoch 220, loss_inner: 1.18166, loss_target: 1.16486, homo loss: 0.00001 
acc_train_clean: 0.6562, ASR_train_attach: 1.0000, ASR_train_outter: 0.9916
Epoch 230, loss_inner: 1.17262, loss_target: 1.15611, homo loss: 0.00001 
acc_train_clean: 0.6581, ASR_train_attach: 1.0000, ASR_train_outter: 0.9916
Epoch 240, loss_inner: 1.16548, loss_target: 1.14915, homo loss: 0.00000 
acc_train_clean: 0.6599, ASR_train_attach: 1.0000, ASR_train_outter: 0.9916
Epoch 250, loss_inner: 1.16054, loss_target: 1.14524, homo loss: 0.00003 
acc_train_clean: 0.6612, ASR_train_attach: 1.0000, ASR_train_outter: 0.9899
Epoch 260, loss_inner: 1.15629, loss_target: 1.13989, homo loss: 0.00000 
acc_train_clean: 0.6629, ASR_train_attach: 1.0000, ASR_train_outter: 0.9916
Epoch 270, loss_inner: 1.15383, loss_target: 1.14748, homo loss: 0.00409 
acc_train_clean: 0.6636, ASR_train_attach: 0.9875, ASR_train_outter: 0.9713
Epoch 280, loss_inner: 1.19425, loss_target: 1.20823, homo loss: 0.00158 
acc_train_clean: 0.6514, ASR_train_attach: 0.9875, ASR_train_outter: 0.9611
Epoch 290, loss_inner: 1.16981, loss_target: 1.18653, homo loss: 0.00152 
acc_train_clean: 0.6591, ASR_train_attach: 0.9500, ASR_train_outter: 0.9645
Epoch 300, loss_inner: 1.15702, loss_target: 1.16092, homo loss: 0.00111 
acc_train_clean: 0.6625, ASR_train_attach: 1.0000, ASR_train_outter: 0.9966
Epoch 310, loss_inner: 1.15028, loss_target: 1.14936, homo loss: 0.00091 
acc_train_clean: 0.6641, ASR_train_attach: 1.0000, ASR_train_outter: 0.9966
Epoch 320, loss_inner: 1.14598, loss_target: 1.14177, homo loss: 0.00083 
acc_train_clean: 0.6651, ASR_train_attach: 1.0000, ASR_train_outter: 0.9966
Epoch 330, loss_inner: 1.14309, loss_target: 1.13786, homo loss: 0.00079 
acc_train_clean: 0.6658, ASR_train_attach: 1.0000, ASR_train_outter: 0.9966
Epoch 340, loss_inner: 1.14076, loss_target: 1.13497, homo loss: 0.00077 
acc_train_clean: 0.6665, ASR_train_attach: 1.0000, ASR_train_outter: 0.9949
Epoch 350, loss_inner: 1.13898, loss_target: 1.13294, homo loss: 0.00076 
acc_train_clean: 0.6672, ASR_train_attach: 1.0000, ASR_train_outter: 0.9949
Epoch 360, loss_inner: 1.13662, loss_target: 1.13030, homo loss: 0.00076 
acc_train_clean: 0.6678, ASR_train_attach: 1.0000, ASR_train_outter: 0.9966
Epoch 370, loss_inner: 1.13333, loss_target: 1.12769, homo loss: 0.00075 
acc_train_clean: 0.6685, ASR_train_attach: 1.0000, ASR_train_outter: 0.9966
Epoch 380, loss_inner: 1.13015, loss_target: 1.12381, homo loss: 0.00075 
acc_train_clean: 0.6697, ASR_train_attach: 1.0000, ASR_train_outter: 0.9966
Epoch 390, loss_inner: 1.12774, loss_target: 1.12146, homo loss: 0.00076 
acc_train_clean: 0.6702, ASR_train_attach: 1.0000, ASR_train_outter: 0.9966
load best weight based on the loss outter
precent of left attach nodes: 1.000
Namespace(cuda=True, dataset='ogbn-arxiv', debug=True, defense_mode='none', device_id=0, dis_weight=1.0, dropout=0.5, epochs=200, evaluate_mode='1by1', hidden=32, homo_boost_thrd=0.8, homo_loss_weight=100.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.8, seed=10, selection_method='none', target_class=0, target_loss_weight=1, test_model='GCN', thrd=0.5, train_lr=0.01, trigger_size=3, trojan_epochs=400, use_vs_number=True, vs_number=80, vs_ratio=0, weight_decay=0.0005)
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.6343
Overall ASR: 0.9845
Flip ASR: 0.9845/16875 nodes
Overall ASR: 0.9845 (GCN model, Seed: 10)
Overall Clean Accuracy: 0.6343
run_adaptive.py:8: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
/home/mfl5681/project-backdoor/Backdoor/models/GAT.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.labels = torch.tensor(labels, dtype=torch.long)
Namespace(cuda=True, dataset='ogbn-arxiv', debug=True, defense_mode='none', device_id=0, dis_weight=1.0, dropout=0.5, epochs=200, evaluate_mode='1by1', hidden=32, homo_boost_thrd=0.8, homo_loss_weight=100.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.8, seed=10, selection_method='none', target_class=0, target_loss_weight=1, test_model='GAT', thrd=0.5, train_lr=0.01, trigger_size=3, trojan_epochs=400, use_vs_number=True, vs_number=80, vs_ratio=0, weight_decay=0.0005)
target class rate on Vs: 1.0000
accuracy on clean test nodes: 0.6490
Overall ASR: 1.0000
Flip ASR: 1.0000/16875 nodes
Overall ASR: 1.0000 (GAT model, Seed: 10)
Overall Clean Accuracy: 0.6490
Namespace(cuda=True, dataset='ogbn-arxiv', debug=True, defense_mode='none', device_id=0, dis_weight=1.0, dropout=0.5, epochs=200, evaluate_mode='1by1', hidden=32, homo_boost_thrd=0.8, homo_loss_weight=100.0, inner=1, lr=0.01, model='GCN', no_cuda=False, prune_thr=0.8, seed=10, selection_method='none', target_class=0, target_loss_weight=1, test_model='GraphSage', thrd=0.5, train_lr=0.01, trigger_size=3, trojan_epochs=400, use_vs_number=True, vs_number=80, vs_ratio=0, weight_decay=0.0005)
target class rate on Vs: 0.9375
accuracy on clean test nodes: 0.6350
Overall ASR: 0.8544
Flip ASR: 0.8539/16875 nodes
Overall ASR: 0.8544 (GraphSage model, Seed: 10)
Overall Clean Accuracy: 0.6350
Total Overall ASR: 0.9463 
Total Clean Accuracy: 0.6394
